{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-12-07T00:10:59.171639Z",
     "iopub.status.busy": "2020-12-07T00:10:59.170808Z",
     "iopub.status.idle": "2020-12-07T00:11:01.064824Z",
     "shell.execute_reply": "2020-12-07T00:11:01.067637Z"
    },
    "papermill": {
     "duration": 1.921501,
     "end_time": "2020-12-07T00:11:01.068900",
     "exception": false,
     "start_time": "2020-12-07T00:10:59.147399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-07T00:11:01.165679Z",
     "iopub.status.busy": "2020-12-07T00:11:01.164640Z",
     "iopub.status.idle": "2020-12-07T00:11:01.207019Z",
     "shell.execute_reply": "2020-12-07T00:11:01.208405Z"
    },
    "papermill": {
     "duration": 0.079061,
     "end_time": "2020-12-07T00:11:01.208614",
     "exception": false,
     "start_time": "2020-12-07T00:11:01.129553",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "random_transforms = [transforms.RandomRotation(degrees=5)]\n",
    "\n",
    "\"\"\"train_transform = transforms.Compose([\n",
    "    transforms.Resize((128,128)),\n",
    "    transforms.RandomCrop(118),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    #transforms.RandomApply(random_transforms, p=0.2),\n",
    "    transforms.RandomAffine(0, translate=(0.02,0.02), scale=None, shear=None, resample=False, fillcolor=0),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomErasing(scale=(0.02, 0.06), ratio=(0.8, 0.8)),\n",
    "    transforms.Normalize([0.1307], [0.3081]),\n",
    "])\"\"\"\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((128,128)),\n",
    "    transforms.RandomCrop(120),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    #transforms.RandomApply(random_transforms, p=0.2),\n",
    "    #transforms.RandomAffine(0, translate=(0.02,0.02), scale=None, shear=None, resample=False, fillcolor=0),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomErasing(scale=(0.00, 0.01), ratio=(0.6, 0.8)),\n",
    "    transforms.RandomErasing(scale=(0.00, 0.01), ratio=(0.6, 0.8)),\n",
    "    transforms.RandomErasing(scale=(0.00, 0.01), ratio=(0.6, 0.8)),\n",
    "    transforms.RandomErasing(scale=(0.00, 0.01), ratio=(0.6, 0.8)),\n",
    "    transforms.RandomErasing(scale=(0.00, 0.01), ratio=(0.6, 0.8)),\n",
    "    transforms.RandomErasing(scale=(0.00, 0.01), ratio=(0.6, 0.8)),\n",
    "    transforms.RandomErasing(scale=(0.00, 0.01), ratio=(0.6, 0.8)),\n",
    "    transforms.RandomErasing(scale=(0.00, 0.01), ratio=(0.6, 0.8)),\n",
    "    transforms.RandomErasing(scale=(0.00, 0.01), ratio=(0.6, 0.8)),\n",
    "    transforms.RandomErasing(scale=(0.00, 0.01), ratio=(0.6, 0.8)),\n",
    "    transforms.RandomErasing(scale=(0.00, 0.01), ratio=(0.6, 0.8)),\n",
    "    transforms.RandomErasing(scale=(0.00, 0.01), ratio=(0.6, 0.8)),\n",
    "    transforms.RandomErasing(scale=(0.00, 0.01), ratio=(0.6, 0.8)),\n",
    "    transforms.RandomErasing(scale=(0.00, 0.01), ratio=(0.6, 0.8)),\n",
    "    transforms.RandomErasing(scale=(0.00, 0.01), ratio=(0.6, 0.8)),\n",
    "    transforms.RandomErasing(scale=(0.00, 0.01), ratio=(0.6, 0.8)),\n",
    "    transforms.RandomErasing(scale=(0.00, 0.01), ratio=(0.6, 0.8)),\n",
    "    transforms.RandomErasing(scale=(0.00, 0.01), ratio=(0.6, 0.8)),\n",
    "    transforms.Normalize([0.1307], [0.3081]),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((128,128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.1307], [0.3081])\n",
    "])\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, labels, transform=None, idx = None):\n",
    "        self.data = data\n",
    "        self.targets = labels\n",
    "        if idx is not None:\n",
    "          self.targets = self.targets[idx]\n",
    "          self.data = self.data[idx]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, target = self.data[index], int(self.targets[index])\n",
    "        img = Image.fromarray(img.astype('uint8'), mode='L')\n",
    "\n",
    "        if self.transform is not None:\n",
    "           img = self.transform(img)\n",
    "\n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-07T00:11:01.279210Z",
     "iopub.status.busy": "2020-12-07T00:11:01.275807Z",
     "iopub.status.idle": "2020-12-07T00:11:07.564459Z",
     "shell.execute_reply": "2020-12-07T00:11:07.565084Z"
    },
    "papermill": {
     "duration": 6.332408,
     "end_time": "2020-12-07T00:11:07.565242",
     "exception": false,
     "start_time": "2020-12-07T00:11:01.232834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "batch_size = 128 #feel free to change it\n",
    "\n",
    "data = pickle.load(open('../input/ecse-551-f20-image-understanding/Train.pkl', 'rb' ), encoding='bytes')\n",
    "targets = np.genfromtxt('../input/ecse-551-f20-image-understanding/TrainLabels.csv', delimiter=',', skip_header=1)[:,1:]\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(data, targets, test_size=0.001, random_state=42)\n",
    "\n",
    "X_train, y_train = data, targets\n",
    "\n",
    "orig_train_dataset = MyDataset(X_train, y_train, transform=train_transform, idx=None)\n",
    "#orig_test_dataset = MyDataset(X_test, y_test, transform=test_transform, idx=None)\n",
    "\n",
    "\n",
    "train_dataset = DataLoader(orig_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "#test_dataset = DataLoader(orig_test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-07T00:11:07.605532Z",
     "iopub.status.busy": "2020-12-07T00:11:07.604781Z",
     "iopub.status.idle": "2020-12-07T00:11:08.457959Z",
     "shell.execute_reply": "2020-12-07T00:11:08.458514Z"
    },
    "papermill": {
     "duration": 0.878098,
     "end_time": "2020-12-07T00:11:08.458662",
     "exception": false,
     "start_time": "2020-12-07T00:11:07.580564",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "examples = enumerate(train_dataset)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "  plt.subplot(2,3,i+1)\n",
    "  plt.tight_layout()\n",
    "  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "  plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-07T00:11:08.497871Z",
     "iopub.status.busy": "2020-12-07T00:11:08.497212Z",
     "iopub.status.idle": "2020-12-07T00:11:08.501870Z",
     "shell.execute_reply": "2020-12-07T00:11:08.501297Z"
    },
    "papermill": {
     "duration": 0.025177,
     "end_time": "2020-12-07T00:11:08.501985",
     "exception": false,
     "start_time": "2020-12-07T00:11:08.476808",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-07T00:11:08.563724Z",
     "iopub.status.busy": "2020-12-07T00:11:08.553037Z",
     "iopub.status.idle": "2020-12-07T00:11:08.615357Z",
     "shell.execute_reply": "2020-12-07T00:11:08.614727Z"
    },
    "papermill": {
     "duration": 0.097397,
     "end_time": "2020-12-07T00:11:08.615469",
     "exception": false,
     "start_time": "2020-12-07T00:11:08.518072",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Type, Any, Callable, Union, List, Optional\n",
    "from torch import Tensor\n",
    "\n",
    "def conv3x3(in_planes: int, out_planes: int, stride: int = 1, groups: int = 1, dilation: int = 1) -> nn.Conv2d:\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes: int, out_planes: int, stride: int = 1) -> nn.Conv2d:\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion: int = 1\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        inplanes: int,\n",
    "        planes: int,\n",
    "        stride: int = 1,\n",
    "        downsample: Optional[nn.Module] = None,\n",
    "        groups: int = 1,\n",
    "        base_width: int = 64,\n",
    "        dilation: int = 1,\n",
    "        norm_layer: Optional[Callable[..., nn.Module]] = None\n",
    "    ) -> None:\n",
    "        super(BasicBlock, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        if groups != 1 or base_width != 64:\n",
    "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
    "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)\n",
    "    # while original implementation places the stride at the first 1x1 convolution(self.conv1)\n",
    "    # according to \"Deep residual learning for image recognition\"https://arxiv.org/abs/1512.03385.\n",
    "    # This variant is also known as ResNet V1.5 and improves accuracy according to\n",
    "    # https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.\n",
    "\n",
    "    expansion: int = 4\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        inplanes: int,\n",
    "        planes: int,\n",
    "        stride: int = 1,\n",
    "        downsample: Optional[nn.Module] = None,\n",
    "        groups: int = 1,\n",
    "        base_width: int = 64,\n",
    "        dilation: int = 1,\n",
    "        norm_layer: Optional[Callable[..., nn.Module]] = None\n",
    "    ) -> None:\n",
    "        super(Bottleneck, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        width = int(planes * (base_width / 64.)) * groups\n",
    "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv1x1(inplanes, width)\n",
    "        self.bn1 = norm_layer(width)\n",
    "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
    "        self.bn2 = norm_layer(width)\n",
    "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
    "        self.bn3 = norm_layer(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        block: Type[Union[BasicBlock, Bottleneck]],\n",
    "        layers: List[int],\n",
    "        num_classes: int = 9,\n",
    "        zero_init_residual: bool = False,\n",
    "        groups: int = 1,\n",
    "        width_per_group: int = 64,\n",
    "        replace_stride_with_dilation: Optional[List[bool]] = None,\n",
    "        norm_layer: Optional[Callable[..., nn.Module]] = None\n",
    "    ) -> None:\n",
    "        super(ResNet, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # each element in the tuple indicates if we should replace\n",
    "            # the 2x2 stride with a dilated convolution instead\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        self.conv1 = nn.Conv2d(1, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[1])\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[2])\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)  # type: ignore[arg-type]\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)  # type: ignore[arg-type]\n",
    "\n",
    "    def _make_layer(self, block: Type[Union[BasicBlock, Bottleneck]], planes: int, blocks: int,\n",
    "                    stride: int = 1, dilate: bool = False) -> nn.Sequential:\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                            self.base_width, previous_dilation, norm_layer))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                                base_width=self.base_width, dilation=self.dilation,\n",
    "                                norm_layer=norm_layer))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _forward_impl(self, x: Tensor) -> Tensor:\n",
    "        # See note [TorchScript super()]\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self._forward_impl(x)\n",
    "\n",
    "\n",
    "def _resnet(\n",
    "    arch: str,\n",
    "    block: Type[Union[BasicBlock, Bottleneck]],\n",
    "    layers: List[int],\n",
    "    pretrained: bool,\n",
    "    progress: bool,\n",
    "    **kwargs: Any\n",
    ") -> ResNet:\n",
    "    model = ResNet(block, layers, **kwargs)\n",
    "    if pretrained:\n",
    "        state_dict = load_state_dict_from_url(model_urls[arch],\n",
    "                                              progress=progress)\n",
    "        model.load_state_dict(state_dict)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet50(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> ResNet:\n",
    "    r\"\"\"ResNet-50 model from\n",
    "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    return _resnet('resnet50', Bottleneck, [3, 4, 6, 3], pretrained, progress,\n",
    "                   **kwargs)\n",
    "\n",
    "def wide_resnet50_2(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> ResNet:\n",
    "    r\"\"\"Wide ResNet-50-2 model from\n",
    "    `\"Wide Residual Networks\" <https://arxiv.org/pdf/1605.07146.pdf>`_.\n",
    "    The model is the same as ResNet except for the bottleneck number of channels\n",
    "    which is twice larger in every block. The number of channels in outer 1x1\n",
    "    convolutions is the same, e.g. last block in ResNet-50 has 2048-512-2048\n",
    "    channels, and in Wide ResNet-50-2 has 2048-1024-2048.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    kwargs['width_per_group'] = 64 * 2\n",
    "    return _resnet('wide_resnet50_2', Bottleneck, [3, 4, 6, 3],\n",
    "                   pretrained, progress, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-07T00:11:09.044021Z",
     "iopub.status.busy": "2020-12-07T00:11:09.042947Z",
     "iopub.status.idle": "2020-12-07T00:11:14.742178Z",
     "shell.execute_reply": "2020-12-07T00:11:14.743011Z"
    },
    "papermill": {
     "duration": 6.110362,
     "end_time": "2020-12-07T00:11:14.743224",
     "exception": false,
     "start_time": "2020-12-07T00:11:08.632862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=9, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "network = wide_resnet50_2().to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "print(network)\n",
    "\n",
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_dataset.dataset) for i in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-07T00:11:14.792640Z",
     "iopub.status.busy": "2020-12-07T00:11:14.792060Z",
     "iopub.status.idle": "2020-12-07T00:11:18.270552Z",
     "shell.execute_reply": "2020-12-07T00:11:18.269983Z"
    },
    "papermill": {
     "duration": 3.501767,
     "end_time": "2020-12-07T00:11:18.270655",
     "exception": false,
     "start_time": "2020-12-07T00:11:14.768888",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#network.load_state_dict(torch.load('../input/wresnet/model_resnet.pth'))\n",
    "#optimizer.load_state_dict(torch.load('/kaggle/working/optimizer_resnet.pth'))\n",
    "network = torch.load('../input/wide-resnet-99766/model_last.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-07T00:11:18.330212Z",
     "iopub.status.busy": "2020-12-07T00:11:18.328325Z",
     "iopub.status.idle": "2020-12-07T00:11:18.330942Z",
     "shell.execute_reply": "2020-12-07T00:11:18.331427Z"
    },
    "papermill": {
     "duration": 0.043373,
     "end_time": "2020-12-07T00:11:18.331541",
     "exception": false,
     "start_time": "2020-12-07T00:11:18.288168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(network.parameters(), lr=0.0001)\n",
    "\n",
    "def train(epoch):\n",
    "  network.train()\n",
    "  correct = 0\n",
    "  for batch_idx, (data, label) in enumerate(train_dataset):\n",
    "        \n",
    "    data = data.to(device)\n",
    "    target = (label - 5).to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    output = network(data)\n",
    "    pred = output.data.max(1, keepdim=True)[1]\n",
    "    correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "    loss = criterion(output, target) #negative log liklhood loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if batch_idx % 20 == 0:\n",
    "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "        epoch, batch_idx * len(data), len(train_dataset.dataset),\n",
    "        100. * batch_idx / len(train_dataset), loss.item()))\n",
    "      train_losses.append(loss.item())\n",
    "      train_counter.append(\n",
    "        (batch_idx*64) + ((epoch-1)*len(train_dataset.dataset)))\n",
    "      torch.save(network.state_dict(), '/kaggle/working/model_resnet.pth')\n",
    "      torch.save(optimizer.state_dict(), '/kaggle/working/optimizer_resnet.pth')\n",
    "    \n",
    "  print('\\nTraining set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    correct, len(train_dataset.dataset),\n",
    "    100. * correct / len(train_dataset.dataset)))\n",
    "\n",
    "def test():\n",
    "  network.eval()\n",
    "  test_loss = 0\n",
    "  correct = 0\n",
    "  with torch.no_grad():\n",
    "    for data, label in test_dataset:\n",
    "        data = data.to(device)\n",
    "        target = (label - 5).to(device)\n",
    "        output = network(data)\n",
    "        test_loss += criterion(output, target).item()\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "        #break\n",
    "        \n",
    "  test_loss /= len(test_dataset.dataset)\n",
    "  test_losses.append(test_loss)\n",
    "  print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format( \n",
    "    test_loss, correct, len(test_dataset.dataset),\n",
    "    100. * correct / len(test_dataset.dataset))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-07T00:11:18.371165Z",
     "iopub.status.busy": "2020-12-07T00:11:18.370412Z",
     "iopub.status.idle": "2020-12-07T05:40:15.325874Z",
     "shell.execute_reply": "2020-12-07T05:40:15.326687Z"
    },
    "papermill": {
     "duration": 19736.978143,
     "end_time": "2020-12-07T05:40:15.326889",
     "exception": false,
     "start_time": "2020-12-07T00:11:18.348746",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.004933\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 0.123333\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.017760\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.037731\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.013941\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.091891\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.015282\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.034687\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.008672\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.014512\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.012433\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.015111\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.041941\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.027164\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.066303\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.076383\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.054135\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.014485\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.044421\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.019902\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.071977\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.032414\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.003984\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.056360\n",
      "\n",
      "Training set: Accuracy: 59338/60000 (99%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.021395\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.015151\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.005462\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.048989\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.007229\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.019226\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.021092\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.061617\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.058131\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.037847\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.055115\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.013157\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.008027\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.036601\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.040965\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.044242\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.023278\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.020205\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.034830\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.019324\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.015943\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.021995\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.131287\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.013996\n",
      "\n",
      "Training set: Accuracy: 59290/60000 (99%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.033620\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.033917\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.021800\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.041084\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.052306\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.028604\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.132668\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.007047\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.037484\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.030969\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.028418\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.006137\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.027565\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.010971\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.001436\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.017264\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.021943\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.037471\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.013544\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.022497\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.043062\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.007328\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.016114\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.012471\n",
      "\n",
      "Training set: Accuracy: 59313/60000 (99%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.049927\n",
      "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 0.048329\n",
      "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 0.006743\n",
      "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 0.027198\n",
      "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 0.042647\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.071661\n",
      "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 0.009668\n",
      "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 0.032729\n",
      "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.017506\n",
      "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 0.011965\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.040679\n",
      "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 0.010368\n",
      "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 0.008380\n",
      "Train Epoch: 4 [33280/60000 (55%)]\tLoss: 0.040540\n",
      "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 0.046846\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.021796\n",
      "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.034672\n",
      "Train Epoch: 4 [43520/60000 (72%)]\tLoss: 0.019898\n",
      "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 0.010137\n",
      "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 0.020902\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.096006\n",
      "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 0.040001\n",
      "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 0.042731\n",
      "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 0.014332\n",
      "\n",
      "Training set: Accuracy: 59339/60000 (99%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.063608\n",
      "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 0.029573\n",
      "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 0.037769\n",
      "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 0.042796\n",
      "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 0.056685\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.006856\n",
      "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 0.032693\n",
      "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 0.011358\n",
      "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.004127\n",
      "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 0.007528\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.025771\n",
      "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 0.106299\n",
      "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 0.008454\n",
      "Train Epoch: 5 [33280/60000 (55%)]\tLoss: 0.018028\n",
      "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 0.026142\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.018849\n",
      "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.029054\n",
      "Train Epoch: 5 [43520/60000 (72%)]\tLoss: 0.009900\n",
      "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 0.003278\n",
      "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 0.031007\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.018156\n",
      "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 0.018365\n",
      "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 0.074195\n",
      "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 0.016142\n",
      "\n",
      "Training set: Accuracy: 59313/60000 (99%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.001720\n",
      "Train Epoch: 6 [2560/60000 (4%)]\tLoss: 0.027930\n",
      "Train Epoch: 6 [5120/60000 (9%)]\tLoss: 0.123135\n",
      "Train Epoch: 6 [7680/60000 (13%)]\tLoss: 0.032401\n",
      "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 0.028629\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.066754\n",
      "Train Epoch: 6 [15360/60000 (26%)]\tLoss: 0.010130\n",
      "Train Epoch: 6 [17920/60000 (30%)]\tLoss: 0.044893\n",
      "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 0.027453\n",
      "Train Epoch: 6 [23040/60000 (38%)]\tLoss: 0.048179\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.012801\n",
      "Train Epoch: 6 [28160/60000 (47%)]\tLoss: 0.042270\n",
      "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 0.051156\n",
      "Train Epoch: 6 [33280/60000 (55%)]\tLoss: 0.079166\n",
      "Train Epoch: 6 [35840/60000 (60%)]\tLoss: 0.047903\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.002419\n",
      "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 0.023852\n",
      "Train Epoch: 6 [43520/60000 (72%)]\tLoss: 0.021038\n",
      "Train Epoch: 6 [46080/60000 (77%)]\tLoss: 0.028318\n",
      "Train Epoch: 6 [48640/60000 (81%)]\tLoss: 0.053785\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.067711\n",
      "Train Epoch: 6 [53760/60000 (90%)]\tLoss: 0.010338\n",
      "Train Epoch: 6 [56320/60000 (94%)]\tLoss: 0.043381\n",
      "Train Epoch: 6 [58880/60000 (98%)]\tLoss: 0.104508\n",
      "\n",
      "Training set: Accuracy: 59318/60000 (99%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.037606\n",
      "Train Epoch: 7 [2560/60000 (4%)]\tLoss: 0.031143\n",
      "Train Epoch: 7 [5120/60000 (9%)]\tLoss: 0.020955\n",
      "Train Epoch: 7 [7680/60000 (13%)]\tLoss: 0.030448\n",
      "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 0.011232\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.013474\n",
      "Train Epoch: 7 [15360/60000 (26%)]\tLoss: 0.008869\n",
      "Train Epoch: 7 [17920/60000 (30%)]\tLoss: 0.007472\n",
      "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 0.034124\n",
      "Train Epoch: 7 [23040/60000 (38%)]\tLoss: 0.012420\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.016154\n",
      "Train Epoch: 7 [28160/60000 (47%)]\tLoss: 0.007164\n",
      "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 0.008945\n",
      "Train Epoch: 7 [33280/60000 (55%)]\tLoss: 0.030178\n",
      "Train Epoch: 7 [35840/60000 (60%)]\tLoss: 0.026685\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.028480\n",
      "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 0.046694\n",
      "Train Epoch: 7 [43520/60000 (72%)]\tLoss: 0.049225\n",
      "Train Epoch: 7 [46080/60000 (77%)]\tLoss: 0.070107\n",
      "Train Epoch: 7 [48640/60000 (81%)]\tLoss: 0.022401\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.024542\n",
      "Train Epoch: 7 [53760/60000 (90%)]\tLoss: 0.022305\n",
      "Train Epoch: 7 [56320/60000 (94%)]\tLoss: 0.014032\n",
      "Train Epoch: 7 [58880/60000 (98%)]\tLoss: 0.006923\n",
      "\n",
      "Training set: Accuracy: 59356/60000 (99%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.043314\n",
      "Train Epoch: 8 [2560/60000 (4%)]\tLoss: 0.059557\n",
      "Train Epoch: 8 [5120/60000 (9%)]\tLoss: 0.042702\n",
      "Train Epoch: 8 [7680/60000 (13%)]\tLoss: 0.023387\n",
      "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 0.060467\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.047151\n",
      "Train Epoch: 8 [15360/60000 (26%)]\tLoss: 0.093281\n",
      "Train Epoch: 8 [17920/60000 (30%)]\tLoss: 0.014043\n",
      "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 0.043344\n",
      "Train Epoch: 8 [23040/60000 (38%)]\tLoss: 0.022122\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.018127\n",
      "Train Epoch: 8 [28160/60000 (47%)]\tLoss: 0.030132\n",
      "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 0.018795\n",
      "Train Epoch: 8 [33280/60000 (55%)]\tLoss: 0.009938\n",
      "Train Epoch: 8 [35840/60000 (60%)]\tLoss: 0.012680\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.045189\n",
      "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 0.007056\n",
      "Train Epoch: 8 [43520/60000 (72%)]\tLoss: 0.050992\n",
      "Train Epoch: 8 [46080/60000 (77%)]\tLoss: 0.007973\n",
      "Train Epoch: 8 [48640/60000 (81%)]\tLoss: 0.033837\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.032381\n",
      "Train Epoch: 8 [53760/60000 (90%)]\tLoss: 0.023338\n",
      "Train Epoch: 8 [56320/60000 (94%)]\tLoss: 0.032549\n",
      "Train Epoch: 8 [58880/60000 (98%)]\tLoss: 0.026693\n",
      "\n",
      "Training set: Accuracy: 59363/60000 (99%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.019918\n",
      "Train Epoch: 9 [2560/60000 (4%)]\tLoss: 0.051997\n",
      "Train Epoch: 9 [5120/60000 (9%)]\tLoss: 0.015982\n",
      "Train Epoch: 9 [7680/60000 (13%)]\tLoss: 0.013741\n",
      "Train Epoch: 9 [10240/60000 (17%)]\tLoss: 0.056523\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.032042\n",
      "Train Epoch: 9 [15360/60000 (26%)]\tLoss: 0.005277\n",
      "Train Epoch: 9 [17920/60000 (30%)]\tLoss: 0.013990\n",
      "Train Epoch: 9 [20480/60000 (34%)]\tLoss: 0.024053\n",
      "Train Epoch: 9 [23040/60000 (38%)]\tLoss: 0.013635\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.023988\n",
      "Train Epoch: 9 [28160/60000 (47%)]\tLoss: 0.029761\n",
      "Train Epoch: 9 [30720/60000 (51%)]\tLoss: 0.022181\n",
      "Train Epoch: 9 [33280/60000 (55%)]\tLoss: 0.036619\n",
      "Train Epoch: 9 [35840/60000 (60%)]\tLoss: 0.014260\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.036592\n",
      "Train Epoch: 9 [40960/60000 (68%)]\tLoss: 0.008724\n",
      "Train Epoch: 9 [43520/60000 (72%)]\tLoss: 0.008406\n",
      "Train Epoch: 9 [46080/60000 (77%)]\tLoss: 0.060222\n",
      "Train Epoch: 9 [48640/60000 (81%)]\tLoss: 0.015977\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.032360\n",
      "Train Epoch: 9 [53760/60000 (90%)]\tLoss: 0.027009\n",
      "Train Epoch: 9 [56320/60000 (94%)]\tLoss: 0.053412\n",
      "Train Epoch: 9 [58880/60000 (98%)]\tLoss: 0.017815\n",
      "\n",
      "Training set: Accuracy: 59333/60000 (99%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.110649\n",
      "Train Epoch: 10 [2560/60000 (4%)]\tLoss: 0.079716\n",
      "Train Epoch: 10 [5120/60000 (9%)]\tLoss: 0.011762\n",
      "Train Epoch: 10 [7680/60000 (13%)]\tLoss: 0.012492\n",
      "Train Epoch: 10 [10240/60000 (17%)]\tLoss: 0.013640\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.031616\n",
      "Train Epoch: 10 [15360/60000 (26%)]\tLoss: 0.022961\n",
      "Train Epoch: 10 [17920/60000 (30%)]\tLoss: 0.062813\n",
      "Train Epoch: 10 [20480/60000 (34%)]\tLoss: 0.013518\n",
      "Train Epoch: 10 [23040/60000 (38%)]\tLoss: 0.027848\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.017566\n",
      "Train Epoch: 10 [28160/60000 (47%)]\tLoss: 0.018148\n",
      "Train Epoch: 10 [30720/60000 (51%)]\tLoss: 0.011480\n",
      "Train Epoch: 10 [33280/60000 (55%)]\tLoss: 0.012299\n",
      "Train Epoch: 10 [35840/60000 (60%)]\tLoss: 0.024278\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.008186\n",
      "Train Epoch: 10 [40960/60000 (68%)]\tLoss: 0.028798\n",
      "Train Epoch: 10 [43520/60000 (72%)]\tLoss: 0.053046\n",
      "Train Epoch: 10 [46080/60000 (77%)]\tLoss: 0.045385\n",
      "Train Epoch: 10 [48640/60000 (81%)]\tLoss: 0.052085\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.011347\n",
      "Train Epoch: 10 [53760/60000 (90%)]\tLoss: 0.089502\n",
      "Train Epoch: 10 [56320/60000 (94%)]\tLoss: 0.005523\n",
      "Train Epoch: 10 [58880/60000 (98%)]\tLoss: 0.005102\n",
      "\n",
      "Training set: Accuracy: 59334/60000 (99%)\n",
      "\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.010564\n",
      "Train Epoch: 11 [2560/60000 (4%)]\tLoss: 0.012547\n",
      "Train Epoch: 11 [5120/60000 (9%)]\tLoss: 0.059706\n",
      "Train Epoch: 11 [7680/60000 (13%)]\tLoss: 0.011411\n",
      "Train Epoch: 11 [10240/60000 (17%)]\tLoss: 0.006007\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 0.045984\n",
      "Train Epoch: 11 [15360/60000 (26%)]\tLoss: 0.026105\n",
      "Train Epoch: 11 [17920/60000 (30%)]\tLoss: 0.023113\n",
      "Train Epoch: 11 [20480/60000 (34%)]\tLoss: 0.046800\n",
      "Train Epoch: 11 [23040/60000 (38%)]\tLoss: 0.017089\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.031896\n",
      "Train Epoch: 11 [28160/60000 (47%)]\tLoss: 0.038198\n",
      "Train Epoch: 11 [30720/60000 (51%)]\tLoss: 0.048694\n",
      "Train Epoch: 11 [33280/60000 (55%)]\tLoss: 0.048891\n",
      "Train Epoch: 11 [35840/60000 (60%)]\tLoss: 0.015473\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 0.011398\n",
      "Train Epoch: 11 [40960/60000 (68%)]\tLoss: 0.007984\n",
      "Train Epoch: 11 [43520/60000 (72%)]\tLoss: 0.023672\n",
      "Train Epoch: 11 [46080/60000 (77%)]\tLoss: 0.016025\n",
      "Train Epoch: 11 [48640/60000 (81%)]\tLoss: 0.047457\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.028846\n",
      "Train Epoch: 11 [53760/60000 (90%)]\tLoss: 0.050485\n",
      "Train Epoch: 11 [56320/60000 (94%)]\tLoss: 0.063224\n",
      "Train Epoch: 11 [58880/60000 (98%)]\tLoss: 0.029729\n",
      "\n",
      "Training set: Accuracy: 59360/60000 (99%)\n",
      "\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.020436\n",
      "Train Epoch: 12 [2560/60000 (4%)]\tLoss: 0.027679\n",
      "Train Epoch: 12 [5120/60000 (9%)]\tLoss: 0.040534\n",
      "Train Epoch: 12 [7680/60000 (13%)]\tLoss: 0.010924\n",
      "Train Epoch: 12 [10240/60000 (17%)]\tLoss: 0.010786\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 0.020286\n",
      "Train Epoch: 12 [15360/60000 (26%)]\tLoss: 0.022326\n",
      "Train Epoch: 12 [17920/60000 (30%)]\tLoss: 0.063110\n",
      "Train Epoch: 12 [20480/60000 (34%)]\tLoss: 0.005591\n",
      "Train Epoch: 12 [23040/60000 (38%)]\tLoss: 0.024011\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 0.070051\n",
      "Train Epoch: 12 [28160/60000 (47%)]\tLoss: 0.026016\n",
      "Train Epoch: 12 [30720/60000 (51%)]\tLoss: 0.083389\n",
      "Train Epoch: 12 [33280/60000 (55%)]\tLoss: 0.016697\n",
      "Train Epoch: 12 [35840/60000 (60%)]\tLoss: 0.066017\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 0.061343\n",
      "Train Epoch: 12 [40960/60000 (68%)]\tLoss: 0.078499\n",
      "Train Epoch: 12 [43520/60000 (72%)]\tLoss: 0.021788\n",
      "Train Epoch: 12 [46080/60000 (77%)]\tLoss: 0.004456\n",
      "Train Epoch: 12 [48640/60000 (81%)]\tLoss: 0.036132\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.022138\n",
      "Train Epoch: 12 [53760/60000 (90%)]\tLoss: 0.049210\n",
      "Train Epoch: 12 [56320/60000 (94%)]\tLoss: 0.021376\n",
      "Train Epoch: 12 [58880/60000 (98%)]\tLoss: 0.015060\n",
      "\n",
      "Training set: Accuracy: 59346/60000 (99%)\n",
      "\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.009486\n",
      "Train Epoch: 13 [2560/60000 (4%)]\tLoss: 0.013974\n",
      "Train Epoch: 13 [5120/60000 (9%)]\tLoss: 0.061005\n",
      "Train Epoch: 13 [7680/60000 (13%)]\tLoss: 0.006360\n",
      "Train Epoch: 13 [10240/60000 (17%)]\tLoss: 0.021140\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 0.046021\n",
      "Train Epoch: 13 [15360/60000 (26%)]\tLoss: 0.011508\n",
      "Train Epoch: 13 [17920/60000 (30%)]\tLoss: 0.020499\n",
      "Train Epoch: 13 [20480/60000 (34%)]\tLoss: 0.009913\n",
      "Train Epoch: 13 [23040/60000 (38%)]\tLoss: 0.011984\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 0.061391\n",
      "Train Epoch: 13 [28160/60000 (47%)]\tLoss: 0.018160\n",
      "Train Epoch: 13 [30720/60000 (51%)]\tLoss: 0.076225\n",
      "Train Epoch: 13 [33280/60000 (55%)]\tLoss: 0.007620\n",
      "Train Epoch: 13 [35840/60000 (60%)]\tLoss: 0.043128\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 0.080536\n",
      "Train Epoch: 13 [40960/60000 (68%)]\tLoss: 0.027194\n",
      "Train Epoch: 13 [43520/60000 (72%)]\tLoss: 0.018947\n",
      "Train Epoch: 13 [46080/60000 (77%)]\tLoss: 0.100072\n",
      "Train Epoch: 13 [48640/60000 (81%)]\tLoss: 0.039261\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.031002\n",
      "Train Epoch: 13 [53760/60000 (90%)]\tLoss: 0.004498\n",
      "Train Epoch: 13 [56320/60000 (94%)]\tLoss: 0.018203\n",
      "Train Epoch: 13 [58880/60000 (98%)]\tLoss: 0.020781\n",
      "\n",
      "Training set: Accuracy: 59375/60000 (99%)\n",
      "\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.013502\n",
      "Train Epoch: 14 [2560/60000 (4%)]\tLoss: 0.008793\n",
      "Train Epoch: 14 [5120/60000 (9%)]\tLoss: 0.005458\n",
      "Train Epoch: 14 [7680/60000 (13%)]\tLoss: 0.052105\n",
      "Train Epoch: 14 [10240/60000 (17%)]\tLoss: 0.027964\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.016404\n",
      "Train Epoch: 14 [15360/60000 (26%)]\tLoss: 0.017718\n",
      "Train Epoch: 14 [17920/60000 (30%)]\tLoss: 0.011788\n",
      "Train Epoch: 14 [20480/60000 (34%)]\tLoss: 0.044709\n",
      "Train Epoch: 14 [23040/60000 (38%)]\tLoss: 0.023403\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.043674\n",
      "Train Epoch: 14 [28160/60000 (47%)]\tLoss: 0.010014\n",
      "Train Epoch: 14 [30720/60000 (51%)]\tLoss: 0.023112\n",
      "Train Epoch: 14 [33280/60000 (55%)]\tLoss: 0.010132\n",
      "Train Epoch: 14 [35840/60000 (60%)]\tLoss: 0.030663\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.030453\n",
      "Train Epoch: 14 [40960/60000 (68%)]\tLoss: 0.025714\n",
      "Train Epoch: 14 [43520/60000 (72%)]\tLoss: 0.047579\n",
      "Train Epoch: 14 [46080/60000 (77%)]\tLoss: 0.025866\n",
      "Train Epoch: 14 [48640/60000 (81%)]\tLoss: 0.010140\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.029278\n",
      "Train Epoch: 14 [53760/60000 (90%)]\tLoss: 0.008993\n",
      "Train Epoch: 14 [56320/60000 (94%)]\tLoss: 0.055381\n",
      "Train Epoch: 14 [58880/60000 (98%)]\tLoss: 0.112980\n",
      "\n",
      "Training set: Accuracy: 59348/60000 (99%)\n",
      "\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.023222\n",
      "Train Epoch: 15 [2560/60000 (4%)]\tLoss: 0.012887\n",
      "Train Epoch: 15 [5120/60000 (9%)]\tLoss: 0.015179\n",
      "Train Epoch: 15 [7680/60000 (13%)]\tLoss: 0.051759\n",
      "Train Epoch: 15 [10240/60000 (17%)]\tLoss: 0.014537\n",
      "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 0.100122\n",
      "Train Epoch: 15 [15360/60000 (26%)]\tLoss: 0.011808\n",
      "Train Epoch: 15 [17920/60000 (30%)]\tLoss: 0.041058\n",
      "Train Epoch: 15 [20480/60000 (34%)]\tLoss: 0.052426\n",
      "Train Epoch: 15 [23040/60000 (38%)]\tLoss: 0.062933\n",
      "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 0.011331\n",
      "Train Epoch: 15 [28160/60000 (47%)]\tLoss: 0.013366\n",
      "Train Epoch: 15 [30720/60000 (51%)]\tLoss: 0.036008\n",
      "Train Epoch: 15 [33280/60000 (55%)]\tLoss: 0.025886\n",
      "Train Epoch: 15 [35840/60000 (60%)]\tLoss: 0.021205\n",
      "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 0.077256\n",
      "Train Epoch: 15 [40960/60000 (68%)]\tLoss: 0.016314\n",
      "Train Epoch: 15 [43520/60000 (72%)]\tLoss: 0.023998\n",
      "Train Epoch: 15 [46080/60000 (77%)]\tLoss: 0.011490\n",
      "Train Epoch: 15 [48640/60000 (81%)]\tLoss: 0.019478\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 0.027386\n",
      "Train Epoch: 15 [53760/60000 (90%)]\tLoss: 0.032773\n",
      "Train Epoch: 15 [56320/60000 (94%)]\tLoss: 0.062607\n",
      "Train Epoch: 15 [58880/60000 (98%)]\tLoss: 0.053337\n",
      "\n",
      "Training set: Accuracy: 59371/60000 (99%)\n",
      "\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.039020\n",
      "Train Epoch: 16 [2560/60000 (4%)]\tLoss: 0.017275\n",
      "Train Epoch: 16 [5120/60000 (9%)]\tLoss: 0.006574\n",
      "Train Epoch: 16 [7680/60000 (13%)]\tLoss: 0.015627\n",
      "Train Epoch: 16 [10240/60000 (17%)]\tLoss: 0.002697\n",
      "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 0.026402\n",
      "Train Epoch: 16 [15360/60000 (26%)]\tLoss: 0.029549\n",
      "Train Epoch: 16 [17920/60000 (30%)]\tLoss: 0.027548\n",
      "Train Epoch: 16 [20480/60000 (34%)]\tLoss: 0.074503\n",
      "Train Epoch: 16 [23040/60000 (38%)]\tLoss: 0.034181\n",
      "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 0.004656\n",
      "Train Epoch: 16 [28160/60000 (47%)]\tLoss: 0.031121\n",
      "Train Epoch: 16 [30720/60000 (51%)]\tLoss: 0.027896\n",
      "Train Epoch: 16 [33280/60000 (55%)]\tLoss: 0.010358\n",
      "Train Epoch: 16 [35840/60000 (60%)]\tLoss: 0.037337\n",
      "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 0.041503\n",
      "Train Epoch: 16 [40960/60000 (68%)]\tLoss: 0.028755\n",
      "Train Epoch: 16 [43520/60000 (72%)]\tLoss: 0.015421\n",
      "Train Epoch: 16 [46080/60000 (77%)]\tLoss: 0.053129\n",
      "Train Epoch: 16 [48640/60000 (81%)]\tLoss: 0.020546\n",
      "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 0.031147\n",
      "Train Epoch: 16 [53760/60000 (90%)]\tLoss: 0.030402\n",
      "Train Epoch: 16 [56320/60000 (94%)]\tLoss: 0.053148\n",
      "Train Epoch: 16 [58880/60000 (98%)]\tLoss: 0.029437\n",
      "\n",
      "Training set: Accuracy: 59312/60000 (99%)\n",
      "\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.030973\n",
      "Train Epoch: 17 [2560/60000 (4%)]\tLoss: 0.107853\n",
      "Train Epoch: 17 [5120/60000 (9%)]\tLoss: 0.037675\n",
      "Train Epoch: 17 [7680/60000 (13%)]\tLoss: 0.043794\n",
      "Train Epoch: 17 [10240/60000 (17%)]\tLoss: 0.004748\n",
      "Train Epoch: 17 [12800/60000 (21%)]\tLoss: 0.009569\n",
      "Train Epoch: 17 [15360/60000 (26%)]\tLoss: 0.034017\n",
      "Train Epoch: 17 [17920/60000 (30%)]\tLoss: 0.020622\n",
      "Train Epoch: 17 [20480/60000 (34%)]\tLoss: 0.009738\n",
      "Train Epoch: 17 [23040/60000 (38%)]\tLoss: 0.035652\n",
      "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 0.062268\n",
      "Train Epoch: 17 [28160/60000 (47%)]\tLoss: 0.015090\n",
      "Train Epoch: 17 [30720/60000 (51%)]\tLoss: 0.030124\n",
      "Train Epoch: 17 [33280/60000 (55%)]\tLoss: 0.014790\n",
      "Train Epoch: 17 [35840/60000 (60%)]\tLoss: 0.009509\n",
      "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 0.007942\n",
      "Train Epoch: 17 [40960/60000 (68%)]\tLoss: 0.043953\n",
      "Train Epoch: 17 [43520/60000 (72%)]\tLoss: 0.017834\n",
      "Train Epoch: 17 [46080/60000 (77%)]\tLoss: 0.037655\n",
      "Train Epoch: 17 [48640/60000 (81%)]\tLoss: 0.077999\n",
      "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 0.029583\n",
      "Train Epoch: 17 [53760/60000 (90%)]\tLoss: 0.025820\n",
      "Train Epoch: 17 [56320/60000 (94%)]\tLoss: 0.045194\n",
      "Train Epoch: 17 [58880/60000 (98%)]\tLoss: 0.053883\n",
      "\n",
      "Training set: Accuracy: 59378/60000 (99%)\n",
      "\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.023478\n",
      "Train Epoch: 18 [2560/60000 (4%)]\tLoss: 0.032559\n",
      "Train Epoch: 18 [5120/60000 (9%)]\tLoss: 0.023875\n",
      "Train Epoch: 18 [7680/60000 (13%)]\tLoss: 0.023615\n",
      "Train Epoch: 18 [10240/60000 (17%)]\tLoss: 0.018130\n",
      "Train Epoch: 18 [12800/60000 (21%)]\tLoss: 0.051835\n",
      "Train Epoch: 18 [15360/60000 (26%)]\tLoss: 0.035688\n",
      "Train Epoch: 18 [17920/60000 (30%)]\tLoss: 0.011067\n",
      "Train Epoch: 18 [20480/60000 (34%)]\tLoss: 0.117919\n",
      "Train Epoch: 18 [23040/60000 (38%)]\tLoss: 0.025874\n",
      "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 0.016065\n",
      "Train Epoch: 18 [28160/60000 (47%)]\tLoss: 0.011992\n",
      "Train Epoch: 18 [30720/60000 (51%)]\tLoss: 0.020281\n",
      "Train Epoch: 18 [33280/60000 (55%)]\tLoss: 0.049010\n",
      "Train Epoch: 18 [35840/60000 (60%)]\tLoss: 0.014185\n",
      "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 0.031500\n",
      "Train Epoch: 18 [40960/60000 (68%)]\tLoss: 0.023557\n",
      "Train Epoch: 18 [43520/60000 (72%)]\tLoss: 0.029915\n",
      "Train Epoch: 18 [46080/60000 (77%)]\tLoss: 0.008937\n",
      "Train Epoch: 18 [48640/60000 (81%)]\tLoss: 0.007459\n",
      "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 0.035460\n",
      "Train Epoch: 18 [53760/60000 (90%)]\tLoss: 0.014941\n",
      "Train Epoch: 18 [56320/60000 (94%)]\tLoss: 0.019450\n",
      "Train Epoch: 18 [58880/60000 (98%)]\tLoss: 0.016237\n",
      "\n",
      "Training set: Accuracy: 59369/60000 (99%)\n",
      "\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.013983\n",
      "Train Epoch: 19 [2560/60000 (4%)]\tLoss: 0.023752\n",
      "Train Epoch: 19 [5120/60000 (9%)]\tLoss: 0.005632\n",
      "Train Epoch: 19 [7680/60000 (13%)]\tLoss: 0.015049\n",
      "Train Epoch: 19 [10240/60000 (17%)]\tLoss: 0.040910\n",
      "Train Epoch: 19 [12800/60000 (21%)]\tLoss: 0.071149\n",
      "Train Epoch: 19 [15360/60000 (26%)]\tLoss: 0.024184\n",
      "Train Epoch: 19 [17920/60000 (30%)]\tLoss: 0.004274\n",
      "Train Epoch: 19 [20480/60000 (34%)]\tLoss: 0.025428\n",
      "Train Epoch: 19 [23040/60000 (38%)]\tLoss: 0.036789\n",
      "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 0.065222\n",
      "Train Epoch: 19 [28160/60000 (47%)]\tLoss: 0.051260\n",
      "Train Epoch: 19 [30720/60000 (51%)]\tLoss: 0.013193\n",
      "Train Epoch: 19 [33280/60000 (55%)]\tLoss: 0.033337\n",
      "Train Epoch: 19 [35840/60000 (60%)]\tLoss: 0.049735\n",
      "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 0.011951\n",
      "Train Epoch: 19 [40960/60000 (68%)]\tLoss: 0.003064\n",
      "Train Epoch: 19 [43520/60000 (72%)]\tLoss: 0.038255\n",
      "Train Epoch: 19 [46080/60000 (77%)]\tLoss: 0.013858\n",
      "Train Epoch: 19 [48640/60000 (81%)]\tLoss: 0.025455\n",
      "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 0.053341\n",
      "Train Epoch: 19 [53760/60000 (90%)]\tLoss: 0.010296\n",
      "Train Epoch: 19 [56320/60000 (94%)]\tLoss: 0.047280\n",
      "Train Epoch: 19 [58880/60000 (98%)]\tLoss: 0.008978\n",
      "\n",
      "Training set: Accuracy: 59372/60000 (99%)\n",
      "\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 0.064141\n",
      "Train Epoch: 20 [2560/60000 (4%)]\tLoss: 0.016435\n",
      "Train Epoch: 20 [5120/60000 (9%)]\tLoss: 0.020929\n",
      "Train Epoch: 20 [7680/60000 (13%)]\tLoss: 0.060217\n",
      "Train Epoch: 20 [10240/60000 (17%)]\tLoss: 0.026740\n",
      "Train Epoch: 20 [12800/60000 (21%)]\tLoss: 0.022053\n",
      "Train Epoch: 20 [15360/60000 (26%)]\tLoss: 0.023839\n",
      "Train Epoch: 20 [17920/60000 (30%)]\tLoss: 0.010455\n",
      "Train Epoch: 20 [20480/60000 (34%)]\tLoss: 0.010405\n",
      "Train Epoch: 20 [23040/60000 (38%)]\tLoss: 0.055586\n",
      "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 0.042469\n",
      "Train Epoch: 20 [28160/60000 (47%)]\tLoss: 0.037451\n",
      "Train Epoch: 20 [30720/60000 (51%)]\tLoss: 0.037275\n",
      "Train Epoch: 20 [33280/60000 (55%)]\tLoss: 0.009354\n",
      "Train Epoch: 20 [35840/60000 (60%)]\tLoss: 0.012121\n",
      "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 0.001933\n",
      "Train Epoch: 20 [40960/60000 (68%)]\tLoss: 0.018353\n",
      "Train Epoch: 20 [43520/60000 (72%)]\tLoss: 0.010477\n",
      "Train Epoch: 20 [46080/60000 (77%)]\tLoss: 0.042132\n",
      "Train Epoch: 20 [48640/60000 (81%)]\tLoss: 0.027918\n",
      "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 0.021811\n",
      "Train Epoch: 20 [53760/60000 (90%)]\tLoss: 0.015337\n",
      "Train Epoch: 20 [56320/60000 (94%)]\tLoss: 0.017414\n",
      "Train Epoch: 20 [58880/60000 (98%)]\tLoss: 0.073606\n",
      "\n",
      "Training set: Accuracy: 59354/60000 (99%)\n",
      "\n",
      "Train Epoch: 21 [0/60000 (0%)]\tLoss: 0.010908\n",
      "Train Epoch: 21 [2560/60000 (4%)]\tLoss: 0.069157\n",
      "Train Epoch: 21 [5120/60000 (9%)]\tLoss: 0.061904\n",
      "Train Epoch: 21 [7680/60000 (13%)]\tLoss: 0.012470\n",
      "Train Epoch: 21 [10240/60000 (17%)]\tLoss: 0.030866\n",
      "Train Epoch: 21 [12800/60000 (21%)]\tLoss: 0.007701\n",
      "Train Epoch: 21 [15360/60000 (26%)]\tLoss: 0.010704\n",
      "Train Epoch: 21 [17920/60000 (30%)]\tLoss: 0.091293\n",
      "Train Epoch: 21 [20480/60000 (34%)]\tLoss: 0.016626\n",
      "Train Epoch: 21 [23040/60000 (38%)]\tLoss: 0.050444\n",
      "Train Epoch: 21 [25600/60000 (43%)]\tLoss: 0.012875\n",
      "Train Epoch: 21 [28160/60000 (47%)]\tLoss: 0.029217\n",
      "Train Epoch: 21 [30720/60000 (51%)]\tLoss: 0.042522\n",
      "Train Epoch: 21 [33280/60000 (55%)]\tLoss: 0.017068\n",
      "Train Epoch: 21 [35840/60000 (60%)]\tLoss: 0.073782\n",
      "Train Epoch: 21 [38400/60000 (64%)]\tLoss: 0.043823\n",
      "Train Epoch: 21 [40960/60000 (68%)]\tLoss: 0.031851\n",
      "Train Epoch: 21 [43520/60000 (72%)]\tLoss: 0.011895\n",
      "Train Epoch: 21 [46080/60000 (77%)]\tLoss: 0.031343\n",
      "Train Epoch: 21 [48640/60000 (81%)]\tLoss: 0.022325\n",
      "Train Epoch: 21 [51200/60000 (85%)]\tLoss: 0.022787\n",
      "Train Epoch: 21 [53760/60000 (90%)]\tLoss: 0.031538\n",
      "Train Epoch: 21 [56320/60000 (94%)]\tLoss: 0.043875\n",
      "Train Epoch: 21 [58880/60000 (98%)]\tLoss: 0.015215\n",
      "\n",
      "Training set: Accuracy: 59397/60000 (99%)\n",
      "\n",
      "Train Epoch: 22 [0/60000 (0%)]\tLoss: 0.026810\n",
      "Train Epoch: 22 [2560/60000 (4%)]\tLoss: 0.037273\n",
      "Train Epoch: 22 [5120/60000 (9%)]\tLoss: 0.029131\n",
      "Train Epoch: 22 [7680/60000 (13%)]\tLoss: 0.027804\n",
      "Train Epoch: 22 [10240/60000 (17%)]\tLoss: 0.023224\n",
      "Train Epoch: 22 [12800/60000 (21%)]\tLoss: 0.015815\n",
      "Train Epoch: 22 [15360/60000 (26%)]\tLoss: 0.009745\n",
      "Train Epoch: 22 [17920/60000 (30%)]\tLoss: 0.010147\n",
      "Train Epoch: 22 [20480/60000 (34%)]\tLoss: 0.030184\n",
      "Train Epoch: 22 [23040/60000 (38%)]\tLoss: 0.016372\n",
      "Train Epoch: 22 [25600/60000 (43%)]\tLoss: 0.033018\n",
      "Train Epoch: 22 [28160/60000 (47%)]\tLoss: 0.032269\n",
      "Train Epoch: 22 [30720/60000 (51%)]\tLoss: 0.003140\n",
      "Train Epoch: 22 [33280/60000 (55%)]\tLoss: 0.005833\n",
      "Train Epoch: 22 [35840/60000 (60%)]\tLoss: 0.016786\n",
      "Train Epoch: 22 [38400/60000 (64%)]\tLoss: 0.004565\n",
      "Train Epoch: 22 [40960/60000 (68%)]\tLoss: 0.009194\n",
      "Train Epoch: 22 [43520/60000 (72%)]\tLoss: 0.017744\n",
      "Train Epoch: 22 [46080/60000 (77%)]\tLoss: 0.013491\n",
      "Train Epoch: 22 [48640/60000 (81%)]\tLoss: 0.016729\n",
      "Train Epoch: 22 [51200/60000 (85%)]\tLoss: 0.035874\n",
      "Train Epoch: 22 [53760/60000 (90%)]\tLoss: 0.041701\n",
      "Train Epoch: 22 [56320/60000 (94%)]\tLoss: 0.063730\n",
      "Train Epoch: 22 [58880/60000 (98%)]\tLoss: 0.033188\n",
      "\n",
      "Training set: Accuracy: 59356/60000 (99%)\n",
      "\n",
      "Train Epoch: 23 [0/60000 (0%)]\tLoss: 0.017895\n",
      "Train Epoch: 23 [2560/60000 (4%)]\tLoss: 0.034563\n",
      "Train Epoch: 23 [5120/60000 (9%)]\tLoss: 0.010992\n",
      "Train Epoch: 23 [7680/60000 (13%)]\tLoss: 0.036395\n",
      "Train Epoch: 23 [10240/60000 (17%)]\tLoss: 0.025866\n",
      "Train Epoch: 23 [12800/60000 (21%)]\tLoss: 0.027001\n",
      "Train Epoch: 23 [15360/60000 (26%)]\tLoss: 0.008750\n",
      "Train Epoch: 23 [17920/60000 (30%)]\tLoss: 0.015694\n",
      "Train Epoch: 23 [20480/60000 (34%)]\tLoss: 0.032178\n",
      "Train Epoch: 23 [23040/60000 (38%)]\tLoss: 0.008752\n",
      "Train Epoch: 23 [25600/60000 (43%)]\tLoss: 0.028364\n",
      "Train Epoch: 23 [28160/60000 (47%)]\tLoss: 0.009761\n",
      "Train Epoch: 23 [30720/60000 (51%)]\tLoss: 0.042250\n",
      "Train Epoch: 23 [33280/60000 (55%)]\tLoss: 0.032990\n",
      "Train Epoch: 23 [35840/60000 (60%)]\tLoss: 0.052131\n",
      "Train Epoch: 23 [38400/60000 (64%)]\tLoss: 0.014467\n",
      "Train Epoch: 23 [40960/60000 (68%)]\tLoss: 0.012757\n",
      "Train Epoch: 23 [43520/60000 (72%)]\tLoss: 0.014632\n",
      "Train Epoch: 23 [46080/60000 (77%)]\tLoss: 0.019857\n",
      "Train Epoch: 23 [48640/60000 (81%)]\tLoss: 0.013095\n",
      "Train Epoch: 23 [51200/60000 (85%)]\tLoss: 0.009613\n",
      "Train Epoch: 23 [53760/60000 (90%)]\tLoss: 0.022090\n",
      "Train Epoch: 23 [56320/60000 (94%)]\tLoss: 0.053646\n",
      "Train Epoch: 23 [58880/60000 (98%)]\tLoss: 0.059757\n",
      "\n",
      "Training set: Accuracy: 59433/60000 (99%)\n",
      "\n",
      "Train Epoch: 24 [0/60000 (0%)]\tLoss: 0.016752\n",
      "Train Epoch: 24 [2560/60000 (4%)]\tLoss: 0.008681\n",
      "Train Epoch: 24 [5120/60000 (9%)]\tLoss: 0.006682\n",
      "Train Epoch: 24 [7680/60000 (13%)]\tLoss: 0.016710\n",
      "Train Epoch: 24 [10240/60000 (17%)]\tLoss: 0.006019\n",
      "Train Epoch: 24 [12800/60000 (21%)]\tLoss: 0.029188\n",
      "Train Epoch: 24 [15360/60000 (26%)]\tLoss: 0.040251\n",
      "Train Epoch: 24 [17920/60000 (30%)]\tLoss: 0.010557\n",
      "Train Epoch: 24 [20480/60000 (34%)]\tLoss: 0.019919\n",
      "Train Epoch: 24 [23040/60000 (38%)]\tLoss: 0.071833\n",
      "Train Epoch: 24 [25600/60000 (43%)]\tLoss: 0.015749\n",
      "Train Epoch: 24 [28160/60000 (47%)]\tLoss: 0.004816\n",
      "Train Epoch: 24 [30720/60000 (51%)]\tLoss: 0.011476\n",
      "Train Epoch: 24 [33280/60000 (55%)]\tLoss: 0.048660\n",
      "Train Epoch: 24 [35840/60000 (60%)]\tLoss: 0.068622\n",
      "Train Epoch: 24 [38400/60000 (64%)]\tLoss: 0.004266\n",
      "Train Epoch: 24 [40960/60000 (68%)]\tLoss: 0.015538\n",
      "Train Epoch: 24 [43520/60000 (72%)]\tLoss: 0.050466\n",
      "Train Epoch: 24 [46080/60000 (77%)]\tLoss: 0.010402\n",
      "Train Epoch: 24 [48640/60000 (81%)]\tLoss: 0.019044\n",
      "Train Epoch: 24 [51200/60000 (85%)]\tLoss: 0.013127\n",
      "Train Epoch: 24 [53760/60000 (90%)]\tLoss: 0.034985\n",
      "Train Epoch: 24 [56320/60000 (94%)]\tLoss: 0.016362\n",
      "Train Epoch: 24 [58880/60000 (98%)]\tLoss: 0.040014\n",
      "\n",
      "Training set: Accuracy: 59393/60000 (99%)\n",
      "\n",
      "Train Epoch: 25 [0/60000 (0%)]\tLoss: 0.029431\n",
      "Train Epoch: 25 [2560/60000 (4%)]\tLoss: 0.035947\n",
      "Train Epoch: 25 [5120/60000 (9%)]\tLoss: 0.035773\n",
      "Train Epoch: 25 [7680/60000 (13%)]\tLoss: 0.011057\n",
      "Train Epoch: 25 [10240/60000 (17%)]\tLoss: 0.024047\n",
      "Train Epoch: 25 [12800/60000 (21%)]\tLoss: 0.012317\n",
      "Train Epoch: 25 [15360/60000 (26%)]\tLoss: 0.003302\n",
      "Train Epoch: 25 [17920/60000 (30%)]\tLoss: 0.006764\n",
      "Train Epoch: 25 [20480/60000 (34%)]\tLoss: 0.033368\n",
      "Train Epoch: 25 [23040/60000 (38%)]\tLoss: 0.008953\n",
      "Train Epoch: 25 [25600/60000 (43%)]\tLoss: 0.016005\n",
      "Train Epoch: 25 [28160/60000 (47%)]\tLoss: 0.040826\n",
      "Train Epoch: 25 [30720/60000 (51%)]\tLoss: 0.016293\n",
      "Train Epoch: 25 [33280/60000 (55%)]\tLoss: 0.025687\n",
      "Train Epoch: 25 [35840/60000 (60%)]\tLoss: 0.004541\n",
      "Train Epoch: 25 [38400/60000 (64%)]\tLoss: 0.022173\n",
      "Train Epoch: 25 [40960/60000 (68%)]\tLoss: 0.029228\n",
      "Train Epoch: 25 [43520/60000 (72%)]\tLoss: 0.012375\n",
      "Train Epoch: 25 [46080/60000 (77%)]\tLoss: 0.014642\n",
      "Train Epoch: 25 [48640/60000 (81%)]\tLoss: 0.024385\n",
      "Train Epoch: 25 [51200/60000 (85%)]\tLoss: 0.065941\n",
      "Train Epoch: 25 [53760/60000 (90%)]\tLoss: 0.014496\n",
      "Train Epoch: 25 [56320/60000 (94%)]\tLoss: 0.050863\n",
      "Train Epoch: 25 [58880/60000 (98%)]\tLoss: 0.060604\n",
      "\n",
      "Training set: Accuracy: 59389/60000 (99%)\n",
      "\n",
      "Train Epoch: 26 [0/60000 (0%)]\tLoss: 0.032698\n",
      "Train Epoch: 26 [2560/60000 (4%)]\tLoss: 0.013664\n",
      "Train Epoch: 26 [5120/60000 (9%)]\tLoss: 0.013932\n",
      "Train Epoch: 26 [7680/60000 (13%)]\tLoss: 0.013251\n",
      "Train Epoch: 26 [10240/60000 (17%)]\tLoss: 0.006707\n",
      "Train Epoch: 26 [12800/60000 (21%)]\tLoss: 0.012276\n",
      "Train Epoch: 26 [15360/60000 (26%)]\tLoss: 0.032588\n",
      "Train Epoch: 26 [17920/60000 (30%)]\tLoss: 0.024375\n",
      "Train Epoch: 26 [20480/60000 (34%)]\tLoss: 0.049170\n",
      "Train Epoch: 26 [23040/60000 (38%)]\tLoss: 0.008394\n",
      "Train Epoch: 26 [25600/60000 (43%)]\tLoss: 0.052622\n",
      "Train Epoch: 26 [28160/60000 (47%)]\tLoss: 0.006292\n",
      "Train Epoch: 26 [30720/60000 (51%)]\tLoss: 0.014729\n",
      "Train Epoch: 26 [33280/60000 (55%)]\tLoss: 0.024167\n",
      "Train Epoch: 26 [35840/60000 (60%)]\tLoss: 0.014686\n",
      "Train Epoch: 26 [38400/60000 (64%)]\tLoss: 0.013427\n",
      "Train Epoch: 26 [40960/60000 (68%)]\tLoss: 0.057605\n",
      "Train Epoch: 26 [43520/60000 (72%)]\tLoss: 0.006624\n",
      "Train Epoch: 26 [46080/60000 (77%)]\tLoss: 0.013221\n",
      "Train Epoch: 26 [48640/60000 (81%)]\tLoss: 0.025244\n",
      "Train Epoch: 26 [51200/60000 (85%)]\tLoss: 0.039363\n",
      "Train Epoch: 26 [53760/60000 (90%)]\tLoss: 0.013698\n",
      "Train Epoch: 26 [56320/60000 (94%)]\tLoss: 0.065308\n",
      "Train Epoch: 26 [58880/60000 (98%)]\tLoss: 0.039314\n",
      "\n",
      "Training set: Accuracy: 59412/60000 (99%)\n",
      "\n",
      "Train Epoch: 27 [0/60000 (0%)]\tLoss: 0.046050\n",
      "Train Epoch: 27 [2560/60000 (4%)]\tLoss: 0.025880\n",
      "Train Epoch: 27 [5120/60000 (9%)]\tLoss: 0.009278\n",
      "Train Epoch: 27 [7680/60000 (13%)]\tLoss: 0.028927\n",
      "Train Epoch: 27 [10240/60000 (17%)]\tLoss: 0.077793\n",
      "Train Epoch: 27 [12800/60000 (21%)]\tLoss: 0.016455\n",
      "Train Epoch: 27 [15360/60000 (26%)]\tLoss: 0.029556\n",
      "Train Epoch: 27 [17920/60000 (30%)]\tLoss: 0.009717\n",
      "Train Epoch: 27 [20480/60000 (34%)]\tLoss: 0.057762\n",
      "Train Epoch: 27 [23040/60000 (38%)]\tLoss: 0.019774\n",
      "Train Epoch: 27 [25600/60000 (43%)]\tLoss: 0.114650\n",
      "Train Epoch: 27 [28160/60000 (47%)]\tLoss: 0.034260\n",
      "Train Epoch: 27 [30720/60000 (51%)]\tLoss: 0.007885\n",
      "Train Epoch: 27 [33280/60000 (55%)]\tLoss: 0.046489\n",
      "Train Epoch: 27 [35840/60000 (60%)]\tLoss: 0.061411\n",
      "Train Epoch: 27 [38400/60000 (64%)]\tLoss: 0.017229\n",
      "Train Epoch: 27 [40960/60000 (68%)]\tLoss: 0.060414\n",
      "Train Epoch: 27 [43520/60000 (72%)]\tLoss: 0.031870\n",
      "Train Epoch: 27 [46080/60000 (77%)]\tLoss: 0.010455\n",
      "Train Epoch: 27 [48640/60000 (81%)]\tLoss: 0.018184\n",
      "Train Epoch: 27 [51200/60000 (85%)]\tLoss: 0.009329\n",
      "Train Epoch: 27 [53760/60000 (90%)]\tLoss: 0.042966\n",
      "Train Epoch: 27 [56320/60000 (94%)]\tLoss: 0.009022\n",
      "Train Epoch: 27 [58880/60000 (98%)]\tLoss: 0.046480\n",
      "\n",
      "Training set: Accuracy: 59376/60000 (99%)\n",
      "\n",
      "Train Epoch: 28 [0/60000 (0%)]\tLoss: 0.016745\n",
      "Train Epoch: 28 [2560/60000 (4%)]\tLoss: 0.007056\n",
      "Train Epoch: 28 [5120/60000 (9%)]\tLoss: 0.027111\n",
      "Train Epoch: 28 [7680/60000 (13%)]\tLoss: 0.024245\n",
      "Train Epoch: 28 [10240/60000 (17%)]\tLoss: 0.021302\n",
      "Train Epoch: 28 [12800/60000 (21%)]\tLoss: 0.031784\n",
      "Train Epoch: 28 [15360/60000 (26%)]\tLoss: 0.018102\n",
      "Train Epoch: 28 [17920/60000 (30%)]\tLoss: 0.005668\n",
      "Train Epoch: 28 [20480/60000 (34%)]\tLoss: 0.015440\n",
      "Train Epoch: 28 [23040/60000 (38%)]\tLoss: 0.043374\n",
      "Train Epoch: 28 [25600/60000 (43%)]\tLoss: 0.061671\n",
      "Train Epoch: 28 [28160/60000 (47%)]\tLoss: 0.028795\n",
      "Train Epoch: 28 [30720/60000 (51%)]\tLoss: 0.009317\n",
      "Train Epoch: 28 [33280/60000 (55%)]\tLoss: 0.072687\n",
      "Train Epoch: 28 [35840/60000 (60%)]\tLoss: 0.045073\n",
      "Train Epoch: 28 [38400/60000 (64%)]\tLoss: 0.020231\n",
      "Train Epoch: 28 [40960/60000 (68%)]\tLoss: 0.026078\n",
      "Train Epoch: 28 [43520/60000 (72%)]\tLoss: 0.051976\n",
      "Train Epoch: 28 [46080/60000 (77%)]\tLoss: 0.019251\n",
      "Train Epoch: 28 [48640/60000 (81%)]\tLoss: 0.040147\n",
      "Train Epoch: 28 [51200/60000 (85%)]\tLoss: 0.009911\n",
      "Train Epoch: 28 [53760/60000 (90%)]\tLoss: 0.039920\n",
      "Train Epoch: 28 [56320/60000 (94%)]\tLoss: 0.047299\n",
      "Train Epoch: 28 [58880/60000 (98%)]\tLoss: 0.012544\n",
      "\n",
      "Training set: Accuracy: 59346/60000 (99%)\n",
      "\n",
      "Train Epoch: 29 [0/60000 (0%)]\tLoss: 0.045934\n",
      "Train Epoch: 29 [2560/60000 (4%)]\tLoss: 0.024159\n",
      "Train Epoch: 29 [5120/60000 (9%)]\tLoss: 0.023690\n",
      "Train Epoch: 29 [7680/60000 (13%)]\tLoss: 0.053887\n",
      "Train Epoch: 29 [10240/60000 (17%)]\tLoss: 0.023405\n",
      "Train Epoch: 29 [12800/60000 (21%)]\tLoss: 0.021405\n",
      "Train Epoch: 29 [15360/60000 (26%)]\tLoss: 0.043566\n",
      "Train Epoch: 29 [17920/60000 (30%)]\tLoss: 0.038754\n",
      "Train Epoch: 29 [20480/60000 (34%)]\tLoss: 0.034673\n",
      "Train Epoch: 29 [23040/60000 (38%)]\tLoss: 0.012371\n",
      "Train Epoch: 29 [25600/60000 (43%)]\tLoss: 0.015671\n",
      "Train Epoch: 29 [28160/60000 (47%)]\tLoss: 0.019805\n",
      "Train Epoch: 29 [30720/60000 (51%)]\tLoss: 0.026876\n",
      "Train Epoch: 29 [33280/60000 (55%)]\tLoss: 0.013967\n",
      "Train Epoch: 29 [35840/60000 (60%)]\tLoss: 0.022992\n",
      "Train Epoch: 29 [38400/60000 (64%)]\tLoss: 0.024164\n",
      "Train Epoch: 29 [40960/60000 (68%)]\tLoss: 0.040129\n",
      "Train Epoch: 29 [43520/60000 (72%)]\tLoss: 0.021302\n",
      "Train Epoch: 29 [46080/60000 (77%)]\tLoss: 0.038640\n",
      "Train Epoch: 29 [48640/60000 (81%)]\tLoss: 0.012985\n",
      "Train Epoch: 29 [51200/60000 (85%)]\tLoss: 0.029010\n",
      "Train Epoch: 29 [53760/60000 (90%)]\tLoss: 0.005446\n",
      "Train Epoch: 29 [56320/60000 (94%)]\tLoss: 0.002184\n",
      "Train Epoch: 29 [58880/60000 (98%)]\tLoss: 0.030472\n",
      "\n",
      "Training set: Accuracy: 59347/60000 (99%)\n",
      "\n",
      "Train Epoch: 30 [0/60000 (0%)]\tLoss: 0.061734\n",
      "Train Epoch: 30 [2560/60000 (4%)]\tLoss: 0.064867\n",
      "Train Epoch: 30 [5120/60000 (9%)]\tLoss: 0.026665\n",
      "Train Epoch: 30 [7680/60000 (13%)]\tLoss: 0.052696\n",
      "Train Epoch: 30 [10240/60000 (17%)]\tLoss: 0.014259\n",
      "Train Epoch: 30 [12800/60000 (21%)]\tLoss: 0.004051\n",
      "Train Epoch: 30 [15360/60000 (26%)]\tLoss: 0.032202\n",
      "Train Epoch: 30 [17920/60000 (30%)]\tLoss: 0.039546\n",
      "Train Epoch: 30 [20480/60000 (34%)]\tLoss: 0.013360\n",
      "Train Epoch: 30 [23040/60000 (38%)]\tLoss: 0.050642\n",
      "Train Epoch: 30 [25600/60000 (43%)]\tLoss: 0.055922\n",
      "Train Epoch: 30 [28160/60000 (47%)]\tLoss: 0.033549\n",
      "Train Epoch: 30 [30720/60000 (51%)]\tLoss: 0.019987\n",
      "Train Epoch: 30 [33280/60000 (55%)]\tLoss: 0.010227\n",
      "Train Epoch: 30 [35840/60000 (60%)]\tLoss: 0.006585\n",
      "Train Epoch: 30 [38400/60000 (64%)]\tLoss: 0.020362\n",
      "Train Epoch: 30 [40960/60000 (68%)]\tLoss: 0.023488\n",
      "Train Epoch: 30 [43520/60000 (72%)]\tLoss: 0.011102\n",
      "Train Epoch: 30 [46080/60000 (77%)]\tLoss: 0.105408\n",
      "Train Epoch: 30 [48640/60000 (81%)]\tLoss: 0.027933\n",
      "Train Epoch: 30 [51200/60000 (85%)]\tLoss: 0.016950\n",
      "Train Epoch: 30 [53760/60000 (90%)]\tLoss: 0.013094\n",
      "Train Epoch: 30 [56320/60000 (94%)]\tLoss: 0.019104\n",
      "Train Epoch: 30 [58880/60000 (98%)]\tLoss: 0.040266\n",
      "\n",
      "Training set: Accuracy: 59404/60000 (99%)\n",
      "\n",
      "Train Epoch: 31 [0/60000 (0%)]\tLoss: 0.007821\n",
      "Train Epoch: 31 [2560/60000 (4%)]\tLoss: 0.086427\n",
      "Train Epoch: 31 [5120/60000 (9%)]\tLoss: 0.028920\n",
      "Train Epoch: 31 [7680/60000 (13%)]\tLoss: 0.049929\n",
      "Train Epoch: 31 [10240/60000 (17%)]\tLoss: 0.010265\n",
      "Train Epoch: 31 [12800/60000 (21%)]\tLoss: 0.051151\n",
      "Train Epoch: 31 [15360/60000 (26%)]\tLoss: 0.050497\n",
      "Train Epoch: 31 [17920/60000 (30%)]\tLoss: 0.032377\n",
      "Train Epoch: 31 [20480/60000 (34%)]\tLoss: 0.034849\n",
      "Train Epoch: 31 [23040/60000 (38%)]\tLoss: 0.017124\n",
      "Train Epoch: 31 [25600/60000 (43%)]\tLoss: 0.034859\n",
      "Train Epoch: 31 [28160/60000 (47%)]\tLoss: 0.007045\n",
      "Train Epoch: 31 [30720/60000 (51%)]\tLoss: 0.028319\n",
      "Train Epoch: 31 [33280/60000 (55%)]\tLoss: 0.009551\n",
      "Train Epoch: 31 [35840/60000 (60%)]\tLoss: 0.042382\n",
      "Train Epoch: 31 [38400/60000 (64%)]\tLoss: 0.017797\n",
      "Train Epoch: 31 [40960/60000 (68%)]\tLoss: 0.009878\n",
      "Train Epoch: 31 [43520/60000 (72%)]\tLoss: 0.022797\n",
      "Train Epoch: 31 [46080/60000 (77%)]\tLoss: 0.035601\n",
      "Train Epoch: 31 [48640/60000 (81%)]\tLoss: 0.006936\n",
      "Train Epoch: 31 [51200/60000 (85%)]\tLoss: 0.010332\n",
      "Train Epoch: 31 [53760/60000 (90%)]\tLoss: 0.010007\n",
      "Train Epoch: 31 [56320/60000 (94%)]\tLoss: 0.010284\n",
      "Train Epoch: 31 [58880/60000 (98%)]\tLoss: 0.015527\n",
      "\n",
      "Training set: Accuracy: 59425/60000 (99%)\n",
      "\n",
      "Train Epoch: 32 [0/60000 (0%)]\tLoss: 0.030267\n",
      "Train Epoch: 32 [2560/60000 (4%)]\tLoss: 0.086044\n",
      "Train Epoch: 32 [5120/60000 (9%)]\tLoss: 0.003259\n",
      "Train Epoch: 32 [7680/60000 (13%)]\tLoss: 0.019116\n",
      "Train Epoch: 32 [10240/60000 (17%)]\tLoss: 0.029287\n",
      "Train Epoch: 32 [12800/60000 (21%)]\tLoss: 0.056138\n",
      "Train Epoch: 32 [15360/60000 (26%)]\tLoss: 0.025764\n",
      "Train Epoch: 32 [17920/60000 (30%)]\tLoss: 0.076281\n",
      "Train Epoch: 32 [20480/60000 (34%)]\tLoss: 0.014862\n",
      "Train Epoch: 32 [23040/60000 (38%)]\tLoss: 0.026082\n",
      "Train Epoch: 32 [25600/60000 (43%)]\tLoss: 0.043541\n",
      "Train Epoch: 32 [28160/60000 (47%)]\tLoss: 0.020137\n",
      "Train Epoch: 32 [30720/60000 (51%)]\tLoss: 0.011393\n",
      "Train Epoch: 32 [33280/60000 (55%)]\tLoss: 0.027357\n",
      "Train Epoch: 32 [35840/60000 (60%)]\tLoss: 0.036946\n",
      "Train Epoch: 32 [38400/60000 (64%)]\tLoss: 0.019237\n",
      "Train Epoch: 32 [40960/60000 (68%)]\tLoss: 0.047185\n",
      "Train Epoch: 32 [43520/60000 (72%)]\tLoss: 0.011644\n",
      "Train Epoch: 32 [46080/60000 (77%)]\tLoss: 0.014760\n",
      "Train Epoch: 32 [48640/60000 (81%)]\tLoss: 0.016287\n",
      "Train Epoch: 32 [51200/60000 (85%)]\tLoss: 0.015978\n",
      "Train Epoch: 32 [53760/60000 (90%)]\tLoss: 0.045478\n",
      "Train Epoch: 32 [56320/60000 (94%)]\tLoss: 0.045766\n",
      "Train Epoch: 32 [58880/60000 (98%)]\tLoss: 0.055342\n",
      "\n",
      "Training set: Accuracy: 59389/60000 (99%)\n",
      "\n",
      "Train Epoch: 33 [0/60000 (0%)]\tLoss: 0.055469\n",
      "Train Epoch: 33 [2560/60000 (4%)]\tLoss: 0.049902\n",
      "Train Epoch: 33 [5120/60000 (9%)]\tLoss: 0.011190\n",
      "Train Epoch: 33 [7680/60000 (13%)]\tLoss: 0.049673\n",
      "Train Epoch: 33 [10240/60000 (17%)]\tLoss: 0.084642\n",
      "Train Epoch: 33 [12800/60000 (21%)]\tLoss: 0.008100\n",
      "Train Epoch: 33 [15360/60000 (26%)]\tLoss: 0.009576\n",
      "Train Epoch: 33 [17920/60000 (30%)]\tLoss: 0.038501\n",
      "Train Epoch: 33 [20480/60000 (34%)]\tLoss: 0.055433\n",
      "Train Epoch: 33 [23040/60000 (38%)]\tLoss: 0.074841\n",
      "Train Epoch: 33 [25600/60000 (43%)]\tLoss: 0.007459\n",
      "Train Epoch: 33 [28160/60000 (47%)]\tLoss: 0.039448\n",
      "Train Epoch: 33 [30720/60000 (51%)]\tLoss: 0.005164\n",
      "Train Epoch: 33 [33280/60000 (55%)]\tLoss: 0.022990\n",
      "Train Epoch: 33 [35840/60000 (60%)]\tLoss: 0.062597\n",
      "Train Epoch: 33 [38400/60000 (64%)]\tLoss: 0.032645\n",
      "Train Epoch: 33 [40960/60000 (68%)]\tLoss: 0.043088\n",
      "Train Epoch: 33 [43520/60000 (72%)]\tLoss: 0.012897\n",
      "Train Epoch: 33 [46080/60000 (77%)]\tLoss: 0.009461\n",
      "Train Epoch: 33 [48640/60000 (81%)]\tLoss: 0.020476\n",
      "Train Epoch: 33 [51200/60000 (85%)]\tLoss: 0.020082\n",
      "Train Epoch: 33 [53760/60000 (90%)]\tLoss: 0.017832\n",
      "Train Epoch: 33 [56320/60000 (94%)]\tLoss: 0.089090\n",
      "Train Epoch: 33 [58880/60000 (98%)]\tLoss: 0.033389\n",
      "\n",
      "Training set: Accuracy: 59325/60000 (99%)\n",
      "\n",
      "Train Epoch: 34 [0/60000 (0%)]\tLoss: 0.044466\n",
      "Train Epoch: 34 [2560/60000 (4%)]\tLoss: 0.056091\n",
      "Train Epoch: 34 [5120/60000 (9%)]\tLoss: 0.017462\n",
      "Train Epoch: 34 [7680/60000 (13%)]\tLoss: 0.008810\n",
      "Train Epoch: 34 [10240/60000 (17%)]\tLoss: 0.027980\n",
      "Train Epoch: 34 [12800/60000 (21%)]\tLoss: 0.006929\n",
      "Train Epoch: 34 [15360/60000 (26%)]\tLoss: 0.015051\n",
      "Train Epoch: 34 [17920/60000 (30%)]\tLoss: 0.016288\n",
      "Train Epoch: 34 [20480/60000 (34%)]\tLoss: 0.021837\n",
      "Train Epoch: 34 [23040/60000 (38%)]\tLoss: 0.077328\n",
      "Train Epoch: 34 [25600/60000 (43%)]\tLoss: 0.070407\n",
      "Train Epoch: 34 [28160/60000 (47%)]\tLoss: 0.029771\n",
      "Train Epoch: 34 [30720/60000 (51%)]\tLoss: 0.008190\n",
      "Train Epoch: 34 [33280/60000 (55%)]\tLoss: 0.019951\n",
      "Train Epoch: 34 [35840/60000 (60%)]\tLoss: 0.010148\n",
      "Train Epoch: 34 [38400/60000 (64%)]\tLoss: 0.016512\n",
      "Train Epoch: 34 [40960/60000 (68%)]\tLoss: 0.007469\n",
      "Train Epoch: 34 [43520/60000 (72%)]\tLoss: 0.006823\n",
      "Train Epoch: 34 [46080/60000 (77%)]\tLoss: 0.060321\n",
      "Train Epoch: 34 [48640/60000 (81%)]\tLoss: 0.025811\n",
      "Train Epoch: 34 [51200/60000 (85%)]\tLoss: 0.015492\n",
      "Train Epoch: 34 [53760/60000 (90%)]\tLoss: 0.015483\n",
      "Train Epoch: 34 [56320/60000 (94%)]\tLoss: 0.026499\n",
      "Train Epoch: 34 [58880/60000 (98%)]\tLoss: 0.049565\n",
      "\n",
      "Training set: Accuracy: 59431/60000 (99%)\n",
      "\n",
      "Train Epoch: 35 [0/60000 (0%)]\tLoss: 0.038757\n",
      "Train Epoch: 35 [2560/60000 (4%)]\tLoss: 0.018111\n",
      "Train Epoch: 35 [5120/60000 (9%)]\tLoss: 0.006513\n",
      "Train Epoch: 35 [7680/60000 (13%)]\tLoss: 0.018103\n",
      "Train Epoch: 35 [10240/60000 (17%)]\tLoss: 0.004121\n",
      "Train Epoch: 35 [12800/60000 (21%)]\tLoss: 0.007430\n",
      "Train Epoch: 35 [15360/60000 (26%)]\tLoss: 0.038967\n",
      "Train Epoch: 35 [17920/60000 (30%)]\tLoss: 0.023407\n",
      "Train Epoch: 35 [20480/60000 (34%)]\tLoss: 0.029339\n",
      "Train Epoch: 35 [23040/60000 (38%)]\tLoss: 0.024703\n",
      "Train Epoch: 35 [25600/60000 (43%)]\tLoss: 0.006716\n",
      "Train Epoch: 35 [28160/60000 (47%)]\tLoss: 0.010078\n",
      "Train Epoch: 35 [30720/60000 (51%)]\tLoss: 0.014228\n",
      "Train Epoch: 35 [33280/60000 (55%)]\tLoss: 0.040979\n",
      "Train Epoch: 35 [35840/60000 (60%)]\tLoss: 0.053345\n",
      "Train Epoch: 35 [38400/60000 (64%)]\tLoss: 0.088634\n",
      "Train Epoch: 35 [40960/60000 (68%)]\tLoss: 0.067768\n",
      "Train Epoch: 35 [43520/60000 (72%)]\tLoss: 0.120571\n",
      "Train Epoch: 35 [46080/60000 (77%)]\tLoss: 0.028868\n",
      "Train Epoch: 35 [48640/60000 (81%)]\tLoss: 0.028139\n",
      "Train Epoch: 35 [51200/60000 (85%)]\tLoss: 0.039213\n",
      "Train Epoch: 35 [53760/60000 (90%)]\tLoss: 0.043413\n",
      "Train Epoch: 35 [56320/60000 (94%)]\tLoss: 0.010382\n",
      "Train Epoch: 35 [58880/60000 (98%)]\tLoss: 0.017616\n",
      "\n",
      "Training set: Accuracy: 59368/60000 (99%)\n",
      "\n",
      "Train Epoch: 36 [0/60000 (0%)]\tLoss: 0.003704\n",
      "Train Epoch: 36 [2560/60000 (4%)]\tLoss: 0.029528\n",
      "Train Epoch: 36 [5120/60000 (9%)]\tLoss: 0.002853\n",
      "Train Epoch: 36 [7680/60000 (13%)]\tLoss: 0.020759\n",
      "Train Epoch: 36 [10240/60000 (17%)]\tLoss: 0.027678\n",
      "Train Epoch: 36 [12800/60000 (21%)]\tLoss: 0.035448\n",
      "Train Epoch: 36 [15360/60000 (26%)]\tLoss: 0.013213\n",
      "Train Epoch: 36 [17920/60000 (30%)]\tLoss: 0.079433\n",
      "Train Epoch: 36 [20480/60000 (34%)]\tLoss: 0.012486\n",
      "Train Epoch: 36 [23040/60000 (38%)]\tLoss: 0.054961\n",
      "Train Epoch: 36 [25600/60000 (43%)]\tLoss: 0.043471\n",
      "Train Epoch: 36 [28160/60000 (47%)]\tLoss: 0.004554\n",
      "Train Epoch: 36 [30720/60000 (51%)]\tLoss: 0.041470\n",
      "Train Epoch: 36 [33280/60000 (55%)]\tLoss: 0.026800\n",
      "Train Epoch: 36 [35840/60000 (60%)]\tLoss: 0.036832\n",
      "Train Epoch: 36 [38400/60000 (64%)]\tLoss: 0.026727\n",
      "Train Epoch: 36 [40960/60000 (68%)]\tLoss: 0.029599\n",
      "Train Epoch: 36 [43520/60000 (72%)]\tLoss: 0.007133\n",
      "Train Epoch: 36 [46080/60000 (77%)]\tLoss: 0.074485\n",
      "Train Epoch: 36 [48640/60000 (81%)]\tLoss: 0.042843\n",
      "Train Epoch: 36 [51200/60000 (85%)]\tLoss: 0.066753\n",
      "Train Epoch: 36 [53760/60000 (90%)]\tLoss: 0.035567\n",
      "Train Epoch: 36 [56320/60000 (94%)]\tLoss: 0.017693\n",
      "Train Epoch: 36 [58880/60000 (98%)]\tLoss: 0.011597\n",
      "\n",
      "Training set: Accuracy: 59394/60000 (99%)\n",
      "\n",
      "Train Epoch: 37 [0/60000 (0%)]\tLoss: 0.041966\n",
      "Train Epoch: 37 [2560/60000 (4%)]\tLoss: 0.006887\n",
      "Train Epoch: 37 [5120/60000 (9%)]\tLoss: 0.030561\n",
      "Train Epoch: 37 [7680/60000 (13%)]\tLoss: 0.017925\n",
      "Train Epoch: 37 [10240/60000 (17%)]\tLoss: 0.025460\n",
      "Train Epoch: 37 [12800/60000 (21%)]\tLoss: 0.076161\n",
      "Train Epoch: 37 [15360/60000 (26%)]\tLoss: 0.009649\n",
      "Train Epoch: 37 [17920/60000 (30%)]\tLoss: 0.010514\n",
      "Train Epoch: 37 [20480/60000 (34%)]\tLoss: 0.015670\n",
      "Train Epoch: 37 [23040/60000 (38%)]\tLoss: 0.034463\n",
      "Train Epoch: 37 [25600/60000 (43%)]\tLoss: 0.050296\n",
      "Train Epoch: 37 [28160/60000 (47%)]\tLoss: 0.006166\n",
      "Train Epoch: 37 [30720/60000 (51%)]\tLoss: 0.024597\n",
      "Train Epoch: 37 [33280/60000 (55%)]\tLoss: 0.066927\n",
      "Train Epoch: 37 [35840/60000 (60%)]\tLoss: 0.016289\n",
      "Train Epoch: 37 [38400/60000 (64%)]\tLoss: 0.015987\n",
      "Train Epoch: 37 [40960/60000 (68%)]\tLoss: 0.018168\n",
      "Train Epoch: 37 [43520/60000 (72%)]\tLoss: 0.027565\n",
      "Train Epoch: 37 [46080/60000 (77%)]\tLoss: 0.007873\n",
      "Train Epoch: 37 [48640/60000 (81%)]\tLoss: 0.053474\n",
      "Train Epoch: 37 [51200/60000 (85%)]\tLoss: 0.004812\n",
      "Train Epoch: 37 [53760/60000 (90%)]\tLoss: 0.055084\n",
      "Train Epoch: 37 [56320/60000 (94%)]\tLoss: 0.046875\n",
      "Train Epoch: 37 [58880/60000 (98%)]\tLoss: 0.012381\n",
      "\n",
      "Training set: Accuracy: 59373/60000 (99%)\n",
      "\n",
      "Train Epoch: 38 [0/60000 (0%)]\tLoss: 0.017232\n",
      "Train Epoch: 38 [2560/60000 (4%)]\tLoss: 0.074814\n",
      "Train Epoch: 38 [5120/60000 (9%)]\tLoss: 0.031763\n",
      "Train Epoch: 38 [7680/60000 (13%)]\tLoss: 0.073012\n",
      "Train Epoch: 38 [10240/60000 (17%)]\tLoss: 0.018227\n",
      "Train Epoch: 38 [12800/60000 (21%)]\tLoss: 0.033511\n",
      "Train Epoch: 38 [15360/60000 (26%)]\tLoss: 0.021613\n",
      "Train Epoch: 38 [17920/60000 (30%)]\tLoss: 0.013296\n",
      "Train Epoch: 38 [20480/60000 (34%)]\tLoss: 0.012492\n",
      "Train Epoch: 38 [23040/60000 (38%)]\tLoss: 0.017425\n",
      "Train Epoch: 38 [25600/60000 (43%)]\tLoss: 0.011418\n",
      "Train Epoch: 38 [28160/60000 (47%)]\tLoss: 0.024804\n",
      "Train Epoch: 38 [30720/60000 (51%)]\tLoss: 0.007778\n",
      "Train Epoch: 38 [33280/60000 (55%)]\tLoss: 0.073230\n",
      "Train Epoch: 38 [35840/60000 (60%)]\tLoss: 0.016423\n",
      "Train Epoch: 38 [38400/60000 (64%)]\tLoss: 0.044597\n",
      "Train Epoch: 38 [40960/60000 (68%)]\tLoss: 0.007092\n",
      "Train Epoch: 38 [43520/60000 (72%)]\tLoss: 0.005639\n",
      "Train Epoch: 38 [46080/60000 (77%)]\tLoss: 0.007245\n",
      "Train Epoch: 38 [48640/60000 (81%)]\tLoss: 0.006874\n",
      "Train Epoch: 38 [51200/60000 (85%)]\tLoss: 0.080026\n",
      "Train Epoch: 38 [53760/60000 (90%)]\tLoss: 0.011295\n",
      "Train Epoch: 38 [56320/60000 (94%)]\tLoss: 0.023101\n",
      "Train Epoch: 38 [58880/60000 (98%)]\tLoss: 0.023430\n",
      "\n",
      "Training set: Accuracy: 59393/60000 (99%)\n",
      "\n",
      "Train Epoch: 39 [0/60000 (0%)]\tLoss: 0.088959\n",
      "Train Epoch: 39 [2560/60000 (4%)]\tLoss: 0.017802\n",
      "Train Epoch: 39 [5120/60000 (9%)]\tLoss: 0.050029\n",
      "Train Epoch: 39 [7680/60000 (13%)]\tLoss: 0.009546\n",
      "Train Epoch: 39 [10240/60000 (17%)]\tLoss: 0.016153\n",
      "Train Epoch: 39 [12800/60000 (21%)]\tLoss: 0.022381\n",
      "Train Epoch: 39 [15360/60000 (26%)]\tLoss: 0.041330\n",
      "Train Epoch: 39 [17920/60000 (30%)]\tLoss: 0.008668\n",
      "Train Epoch: 39 [20480/60000 (34%)]\tLoss: 0.051415\n",
      "Train Epoch: 39 [23040/60000 (38%)]\tLoss: 0.053096\n",
      "Train Epoch: 39 [25600/60000 (43%)]\tLoss: 0.006484\n",
      "Train Epoch: 39 [28160/60000 (47%)]\tLoss: 0.013825\n",
      "Train Epoch: 39 [30720/60000 (51%)]\tLoss: 0.034252\n",
      "Train Epoch: 39 [33280/60000 (55%)]\tLoss: 0.068528\n",
      "Train Epoch: 39 [35840/60000 (60%)]\tLoss: 0.017486\n",
      "Train Epoch: 39 [38400/60000 (64%)]\tLoss: 0.077871\n",
      "Train Epoch: 39 [40960/60000 (68%)]\tLoss: 0.026023\n",
      "Train Epoch: 39 [43520/60000 (72%)]\tLoss: 0.070807\n",
      "Train Epoch: 39 [46080/60000 (77%)]\tLoss: 0.042417\n",
      "Train Epoch: 39 [48640/60000 (81%)]\tLoss: 0.014745\n",
      "Train Epoch: 39 [51200/60000 (85%)]\tLoss: 0.016048\n",
      "Train Epoch: 39 [53760/60000 (90%)]\tLoss: 0.025049\n",
      "Train Epoch: 39 [56320/60000 (94%)]\tLoss: 0.024895\n",
      "Train Epoch: 39 [58880/60000 (98%)]\tLoss: 0.021451\n",
      "\n",
      "Training set: Accuracy: 59434/60000 (99%)\n",
      "\n",
      "Train Epoch: 40 [0/60000 (0%)]\tLoss: 0.065255\n",
      "Train Epoch: 40 [2560/60000 (4%)]\tLoss: 0.016101\n",
      "Train Epoch: 40 [5120/60000 (9%)]\tLoss: 0.005965\n",
      "Train Epoch: 40 [7680/60000 (13%)]\tLoss: 0.048510\n",
      "Train Epoch: 40 [10240/60000 (17%)]\tLoss: 0.016976\n",
      "Train Epoch: 40 [12800/60000 (21%)]\tLoss: 0.023618\n",
      "Train Epoch: 40 [15360/60000 (26%)]\tLoss: 0.017632\n",
      "Train Epoch: 40 [17920/60000 (30%)]\tLoss: 0.073152\n",
      "Train Epoch: 40 [20480/60000 (34%)]\tLoss: 0.025807\n",
      "Train Epoch: 40 [23040/60000 (38%)]\tLoss: 0.044371\n",
      "Train Epoch: 40 [25600/60000 (43%)]\tLoss: 0.014914\n",
      "Train Epoch: 40 [28160/60000 (47%)]\tLoss: 0.009074\n",
      "Train Epoch: 40 [30720/60000 (51%)]\tLoss: 0.018584\n",
      "Train Epoch: 40 [33280/60000 (55%)]\tLoss: 0.030060\n",
      "Train Epoch: 40 [35840/60000 (60%)]\tLoss: 0.007863\n",
      "Train Epoch: 40 [38400/60000 (64%)]\tLoss: 0.034056\n",
      "Train Epoch: 40 [40960/60000 (68%)]\tLoss: 0.017855\n",
      "Train Epoch: 40 [43520/60000 (72%)]\tLoss: 0.020790\n",
      "Train Epoch: 40 [46080/60000 (77%)]\tLoss: 0.017255\n",
      "Train Epoch: 40 [48640/60000 (81%)]\tLoss: 0.015141\n",
      "Train Epoch: 40 [51200/60000 (85%)]\tLoss: 0.021220\n",
      "Train Epoch: 40 [53760/60000 (90%)]\tLoss: 0.059226\n",
      "Train Epoch: 40 [56320/60000 (94%)]\tLoss: 0.029716\n",
      "Train Epoch: 40 [58880/60000 (98%)]\tLoss: 0.016237\n",
      "\n",
      "Training set: Accuracy: 59423/60000 (99%)\n",
      "\n",
      "Train Epoch: 41 [0/60000 (0%)]\tLoss: 0.011931\n",
      "Train Epoch: 41 [2560/60000 (4%)]\tLoss: 0.012734\n",
      "Train Epoch: 41 [5120/60000 (9%)]\tLoss: 0.005335\n",
      "Train Epoch: 41 [7680/60000 (13%)]\tLoss: 0.041610\n",
      "Train Epoch: 41 [10240/60000 (17%)]\tLoss: 0.042602\n",
      "Train Epoch: 41 [12800/60000 (21%)]\tLoss: 0.045349\n",
      "Train Epoch: 41 [15360/60000 (26%)]\tLoss: 0.035911\n",
      "Train Epoch: 41 [17920/60000 (30%)]\tLoss: 0.026782\n",
      "Train Epoch: 41 [20480/60000 (34%)]\tLoss: 0.011768\n",
      "Train Epoch: 41 [23040/60000 (38%)]\tLoss: 0.045986\n",
      "Train Epoch: 41 [25600/60000 (43%)]\tLoss: 0.031080\n",
      "Train Epoch: 41 [28160/60000 (47%)]\tLoss: 0.005185\n",
      "Train Epoch: 41 [30720/60000 (51%)]\tLoss: 0.029612\n",
      "Train Epoch: 41 [33280/60000 (55%)]\tLoss: 0.018690\n",
      "Train Epoch: 41 [35840/60000 (60%)]\tLoss: 0.008489\n",
      "Train Epoch: 41 [38400/60000 (64%)]\tLoss: 0.018843\n",
      "Train Epoch: 41 [40960/60000 (68%)]\tLoss: 0.016863\n",
      "Train Epoch: 41 [43520/60000 (72%)]\tLoss: 0.011794\n",
      "Train Epoch: 41 [46080/60000 (77%)]\tLoss: 0.003776\n",
      "Train Epoch: 41 [48640/60000 (81%)]\tLoss: 0.080414\n",
      "Train Epoch: 41 [51200/60000 (85%)]\tLoss: 0.053224\n",
      "Train Epoch: 41 [53760/60000 (90%)]\tLoss: 0.006770\n",
      "Train Epoch: 41 [56320/60000 (94%)]\tLoss: 0.011581\n",
      "Train Epoch: 41 [58880/60000 (98%)]\tLoss: 0.028998\n",
      "\n",
      "Training set: Accuracy: 59372/60000 (99%)\n",
      "\n",
      "Train Epoch: 42 [0/60000 (0%)]\tLoss: 0.035382\n",
      "Train Epoch: 42 [2560/60000 (4%)]\tLoss: 0.005980\n",
      "Train Epoch: 42 [5120/60000 (9%)]\tLoss: 0.015533\n",
      "Train Epoch: 42 [7680/60000 (13%)]\tLoss: 0.028940\n",
      "Train Epoch: 42 [10240/60000 (17%)]\tLoss: 0.038059\n",
      "Train Epoch: 42 [12800/60000 (21%)]\tLoss: 0.041331\n",
      "Train Epoch: 42 [15360/60000 (26%)]\tLoss: 0.028296\n",
      "Train Epoch: 42 [17920/60000 (30%)]\tLoss: 0.066694\n",
      "Train Epoch: 42 [20480/60000 (34%)]\tLoss: 0.038768\n",
      "Train Epoch: 42 [23040/60000 (38%)]\tLoss: 0.027825\n",
      "Train Epoch: 42 [25600/60000 (43%)]\tLoss: 0.013561\n",
      "Train Epoch: 42 [28160/60000 (47%)]\tLoss: 0.052101\n",
      "Train Epoch: 42 [30720/60000 (51%)]\tLoss: 0.009359\n",
      "Train Epoch: 42 [33280/60000 (55%)]\tLoss: 0.042345\n",
      "Train Epoch: 42 [35840/60000 (60%)]\tLoss: 0.028901\n",
      "Train Epoch: 42 [38400/60000 (64%)]\tLoss: 0.030915\n",
      "Train Epoch: 42 [40960/60000 (68%)]\tLoss: 0.034658\n",
      "Train Epoch: 42 [43520/60000 (72%)]\tLoss: 0.022566\n",
      "Train Epoch: 42 [46080/60000 (77%)]\tLoss: 0.006647\n",
      "Train Epoch: 42 [48640/60000 (81%)]\tLoss: 0.021510\n",
      "Train Epoch: 42 [51200/60000 (85%)]\tLoss: 0.010770\n",
      "Train Epoch: 42 [53760/60000 (90%)]\tLoss: 0.004326\n",
      "Train Epoch: 42 [56320/60000 (94%)]\tLoss: 0.062953\n",
      "Train Epoch: 42 [58880/60000 (98%)]\tLoss: 0.024702\n",
      "\n",
      "Training set: Accuracy: 59366/60000 (99%)\n",
      "\n",
      "Train Epoch: 43 [0/60000 (0%)]\tLoss: 0.003939\n",
      "Train Epoch: 43 [2560/60000 (4%)]\tLoss: 0.053116\n",
      "Train Epoch: 43 [5120/60000 (9%)]\tLoss: 0.064616\n",
      "Train Epoch: 43 [7680/60000 (13%)]\tLoss: 0.019665\n",
      "Train Epoch: 43 [10240/60000 (17%)]\tLoss: 0.013004\n",
      "Train Epoch: 43 [12800/60000 (21%)]\tLoss: 0.091065\n",
      "Train Epoch: 43 [15360/60000 (26%)]\tLoss: 0.027901\n",
      "Train Epoch: 43 [17920/60000 (30%)]\tLoss: 0.014569\n",
      "Train Epoch: 43 [20480/60000 (34%)]\tLoss: 0.006079\n",
      "Train Epoch: 43 [23040/60000 (38%)]\tLoss: 0.015587\n",
      "Train Epoch: 43 [25600/60000 (43%)]\tLoss: 0.020361\n",
      "Train Epoch: 43 [28160/60000 (47%)]\tLoss: 0.030992\n",
      "Train Epoch: 43 [30720/60000 (51%)]\tLoss: 0.036631\n",
      "Train Epoch: 43 [33280/60000 (55%)]\tLoss: 0.044293\n",
      "Train Epoch: 43 [35840/60000 (60%)]\tLoss: 0.008728\n",
      "Train Epoch: 43 [38400/60000 (64%)]\tLoss: 0.006486\n",
      "Train Epoch: 43 [40960/60000 (68%)]\tLoss: 0.017995\n",
      "Train Epoch: 43 [43520/60000 (72%)]\tLoss: 0.062274\n",
      "Train Epoch: 43 [46080/60000 (77%)]\tLoss: 0.009623\n",
      "Train Epoch: 43 [48640/60000 (81%)]\tLoss: 0.012886\n",
      "Train Epoch: 43 [51200/60000 (85%)]\tLoss: 0.006307\n",
      "Train Epoch: 43 [53760/60000 (90%)]\tLoss: 0.065774\n",
      "Train Epoch: 43 [56320/60000 (94%)]\tLoss: 0.013950\n",
      "Train Epoch: 43 [58880/60000 (98%)]\tLoss: 0.032363\n",
      "\n",
      "Training set: Accuracy: 59402/60000 (99%)\n",
      "\n",
      "Train Epoch: 44 [0/60000 (0%)]\tLoss: 0.085772\n",
      "Train Epoch: 44 [2560/60000 (4%)]\tLoss: 0.038716\n",
      "Train Epoch: 44 [5120/60000 (9%)]\tLoss: 0.011198\n",
      "Train Epoch: 44 [7680/60000 (13%)]\tLoss: 0.004764\n",
      "Train Epoch: 44 [10240/60000 (17%)]\tLoss: 0.023587\n",
      "Train Epoch: 44 [12800/60000 (21%)]\tLoss: 0.031076\n",
      "Train Epoch: 44 [15360/60000 (26%)]\tLoss: 0.010425\n",
      "Train Epoch: 44 [17920/60000 (30%)]\tLoss: 0.006819\n",
      "Train Epoch: 44 [20480/60000 (34%)]\tLoss: 0.031127\n",
      "Train Epoch: 44 [23040/60000 (38%)]\tLoss: 0.034173\n",
      "Train Epoch: 44 [25600/60000 (43%)]\tLoss: 0.031387\n",
      "Train Epoch: 44 [28160/60000 (47%)]\tLoss: 0.004364\n",
      "Train Epoch: 44 [30720/60000 (51%)]\tLoss: 0.031463\n",
      "Train Epoch: 44 [33280/60000 (55%)]\tLoss: 0.078694\n",
      "Train Epoch: 44 [35840/60000 (60%)]\tLoss: 0.044241\n",
      "Train Epoch: 44 [38400/60000 (64%)]\tLoss: 0.062153\n",
      "Train Epoch: 44 [40960/60000 (68%)]\tLoss: 0.117107\n",
      "Train Epoch: 44 [43520/60000 (72%)]\tLoss: 0.021933\n",
      "Train Epoch: 44 [46080/60000 (77%)]\tLoss: 0.048977\n",
      "Train Epoch: 44 [48640/60000 (81%)]\tLoss: 0.010844\n",
      "Train Epoch: 44 [51200/60000 (85%)]\tLoss: 0.043595\n",
      "Train Epoch: 44 [53760/60000 (90%)]\tLoss: 0.009896\n",
      "Train Epoch: 44 [56320/60000 (94%)]\tLoss: 0.029189\n",
      "Train Epoch: 44 [58880/60000 (98%)]\tLoss: 0.019323\n",
      "\n",
      "Training set: Accuracy: 59463/60000 (99%)\n",
      "\n",
      "Train Epoch: 45 [0/60000 (0%)]\tLoss: 0.009530\n",
      "Train Epoch: 45 [2560/60000 (4%)]\tLoss: 0.021961\n",
      "Train Epoch: 45 [5120/60000 (9%)]\tLoss: 0.046182\n",
      "Train Epoch: 45 [7680/60000 (13%)]\tLoss: 0.016336\n",
      "Train Epoch: 45 [10240/60000 (17%)]\tLoss: 0.019507\n",
      "Train Epoch: 45 [12800/60000 (21%)]\tLoss: 0.028173\n",
      "Train Epoch: 45 [15360/60000 (26%)]\tLoss: 0.007685\n",
      "Train Epoch: 45 [17920/60000 (30%)]\tLoss: 0.046935\n",
      "Train Epoch: 45 [20480/60000 (34%)]\tLoss: 0.029556\n",
      "Train Epoch: 45 [23040/60000 (38%)]\tLoss: 0.007428\n",
      "Train Epoch: 45 [25600/60000 (43%)]\tLoss: 0.011896\n",
      "Train Epoch: 45 [28160/60000 (47%)]\tLoss: 0.012355\n",
      "Train Epoch: 45 [30720/60000 (51%)]\tLoss: 0.022950\n",
      "Train Epoch: 45 [33280/60000 (55%)]\tLoss: 0.011448\n",
      "Train Epoch: 45 [35840/60000 (60%)]\tLoss: 0.015111\n",
      "Train Epoch: 45 [38400/60000 (64%)]\tLoss: 0.018095\n",
      "Train Epoch: 45 [40960/60000 (68%)]\tLoss: 0.081839\n",
      "Train Epoch: 45 [43520/60000 (72%)]\tLoss: 0.018412\n",
      "Train Epoch: 45 [46080/60000 (77%)]\tLoss: 0.017775\n",
      "Train Epoch: 45 [48640/60000 (81%)]\tLoss: 0.007930\n",
      "Train Epoch: 45 [51200/60000 (85%)]\tLoss: 0.020445\n",
      "Train Epoch: 45 [53760/60000 (90%)]\tLoss: 0.067646\n",
      "Train Epoch: 45 [56320/60000 (94%)]\tLoss: 0.037256\n",
      "Train Epoch: 45 [58880/60000 (98%)]\tLoss: 0.036770\n",
      "\n",
      "Training set: Accuracy: 59409/60000 (99%)\n",
      "\n",
      "Train Epoch: 46 [0/60000 (0%)]\tLoss: 0.068112\n",
      "Train Epoch: 46 [2560/60000 (4%)]\tLoss: 0.067746\n",
      "Train Epoch: 46 [5120/60000 (9%)]\tLoss: 0.001989\n",
      "Train Epoch: 46 [7680/60000 (13%)]\tLoss: 0.024367\n",
      "Train Epoch: 46 [10240/60000 (17%)]\tLoss: 0.038435\n",
      "Train Epoch: 46 [12800/60000 (21%)]\tLoss: 0.019482\n",
      "Train Epoch: 46 [15360/60000 (26%)]\tLoss: 0.014581\n",
      "Train Epoch: 46 [17920/60000 (30%)]\tLoss: 0.037504\n",
      "Train Epoch: 46 [20480/60000 (34%)]\tLoss: 0.013199\n",
      "Train Epoch: 46 [23040/60000 (38%)]\tLoss: 0.013047\n",
      "Train Epoch: 46 [25600/60000 (43%)]\tLoss: 0.010573\n",
      "Train Epoch: 46 [28160/60000 (47%)]\tLoss: 0.020171\n",
      "Train Epoch: 46 [30720/60000 (51%)]\tLoss: 0.012831\n",
      "Train Epoch: 46 [33280/60000 (55%)]\tLoss: 0.005543\n",
      "Train Epoch: 46 [35840/60000 (60%)]\tLoss: 0.006930\n",
      "Train Epoch: 46 [38400/60000 (64%)]\tLoss: 0.024909\n",
      "Train Epoch: 46 [40960/60000 (68%)]\tLoss: 0.010320\n",
      "Train Epoch: 46 [43520/60000 (72%)]\tLoss: 0.107484\n",
      "Train Epoch: 46 [46080/60000 (77%)]\tLoss: 0.023940\n",
      "Train Epoch: 46 [48640/60000 (81%)]\tLoss: 0.011334\n",
      "Train Epoch: 46 [51200/60000 (85%)]\tLoss: 0.033160\n",
      "Train Epoch: 46 [53760/60000 (90%)]\tLoss: 0.012484\n",
      "Train Epoch: 46 [56320/60000 (94%)]\tLoss: 0.033269\n",
      "Train Epoch: 46 [58880/60000 (98%)]\tLoss: 0.011953\n",
      "\n",
      "Training set: Accuracy: 59411/60000 (99%)\n",
      "\n",
      "Train Epoch: 47 [0/60000 (0%)]\tLoss: 0.099031\n",
      "Train Epoch: 47 [2560/60000 (4%)]\tLoss: 0.035446\n",
      "Train Epoch: 47 [5120/60000 (9%)]\tLoss: 0.008059\n",
      "Train Epoch: 47 [7680/60000 (13%)]\tLoss: 0.028195\n",
      "Train Epoch: 47 [10240/60000 (17%)]\tLoss: 0.025921\n",
      "Train Epoch: 47 [12800/60000 (21%)]\tLoss: 0.022993\n",
      "Train Epoch: 47 [15360/60000 (26%)]\tLoss: 0.042457\n",
      "Train Epoch: 47 [17920/60000 (30%)]\tLoss: 0.006294\n",
      "Train Epoch: 47 [20480/60000 (34%)]\tLoss: 0.047033\n",
      "Train Epoch: 47 [23040/60000 (38%)]\tLoss: 0.024492\n",
      "Train Epoch: 47 [25600/60000 (43%)]\tLoss: 0.103404\n",
      "Train Epoch: 47 [28160/60000 (47%)]\tLoss: 0.009831\n",
      "Train Epoch: 47 [30720/60000 (51%)]\tLoss: 0.079273\n",
      "Train Epoch: 47 [33280/60000 (55%)]\tLoss: 0.014581\n",
      "Train Epoch: 47 [35840/60000 (60%)]\tLoss: 0.021155\n",
      "Train Epoch: 47 [38400/60000 (64%)]\tLoss: 0.012398\n",
      "Train Epoch: 47 [40960/60000 (68%)]\tLoss: 0.008515\n",
      "Train Epoch: 47 [43520/60000 (72%)]\tLoss: 0.007408\n",
      "Train Epoch: 47 [46080/60000 (77%)]\tLoss: 0.013809\n",
      "Train Epoch: 47 [48640/60000 (81%)]\tLoss: 0.033429\n",
      "Train Epoch: 47 [51200/60000 (85%)]\tLoss: 0.015159\n",
      "Train Epoch: 47 [53760/60000 (90%)]\tLoss: 0.017827\n",
      "Train Epoch: 47 [56320/60000 (94%)]\tLoss: 0.008719\n",
      "Train Epoch: 47 [58880/60000 (98%)]\tLoss: 0.022443\n",
      "\n",
      "Training set: Accuracy: 59375/60000 (99%)\n",
      "\n",
      "Train Epoch: 48 [0/60000 (0%)]\tLoss: 0.047499\n",
      "Train Epoch: 48 [2560/60000 (4%)]\tLoss: 0.019551\n",
      "Train Epoch: 48 [5120/60000 (9%)]\tLoss: 0.028423\n",
      "Train Epoch: 48 [7680/60000 (13%)]\tLoss: 0.030823\n",
      "Train Epoch: 48 [10240/60000 (17%)]\tLoss: 0.011080\n",
      "Train Epoch: 48 [12800/60000 (21%)]\tLoss: 0.035965\n",
      "Train Epoch: 48 [15360/60000 (26%)]\tLoss: 0.011664\n",
      "Train Epoch: 48 [17920/60000 (30%)]\tLoss: 0.019483\n",
      "Train Epoch: 48 [20480/60000 (34%)]\tLoss: 0.024938\n",
      "Train Epoch: 48 [23040/60000 (38%)]\tLoss: 0.037434\n",
      "Train Epoch: 48 [25600/60000 (43%)]\tLoss: 0.013686\n",
      "Train Epoch: 48 [28160/60000 (47%)]\tLoss: 0.004194\n",
      "Train Epoch: 48 [30720/60000 (51%)]\tLoss: 0.028375\n",
      "Train Epoch: 48 [33280/60000 (55%)]\tLoss: 0.005206\n",
      "Train Epoch: 48 [35840/60000 (60%)]\tLoss: 0.052693\n",
      "Train Epoch: 48 [38400/60000 (64%)]\tLoss: 0.009734\n",
      "Train Epoch: 48 [40960/60000 (68%)]\tLoss: 0.025631\n",
      "Train Epoch: 48 [43520/60000 (72%)]\tLoss: 0.017278\n",
      "Train Epoch: 48 [46080/60000 (77%)]\tLoss: 0.016113\n",
      "Train Epoch: 48 [48640/60000 (81%)]\tLoss: 0.070926\n",
      "Train Epoch: 48 [51200/60000 (85%)]\tLoss: 0.010722\n",
      "Train Epoch: 48 [53760/60000 (90%)]\tLoss: 0.010183\n",
      "Train Epoch: 48 [56320/60000 (94%)]\tLoss: 0.009171\n",
      "Train Epoch: 48 [58880/60000 (98%)]\tLoss: 0.030097\n",
      "\n",
      "Training set: Accuracy: 59404/60000 (99%)\n",
      "\n",
      "Train Epoch: 49 [0/60000 (0%)]\tLoss: 0.022979\n",
      "Train Epoch: 49 [2560/60000 (4%)]\tLoss: 0.083513\n",
      "Train Epoch: 49 [5120/60000 (9%)]\tLoss: 0.016124\n",
      "Train Epoch: 49 [7680/60000 (13%)]\tLoss: 0.029865\n",
      "Train Epoch: 49 [10240/60000 (17%)]\tLoss: 0.032515\n",
      "Train Epoch: 49 [12800/60000 (21%)]\tLoss: 0.058252\n",
      "Train Epoch: 49 [15360/60000 (26%)]\tLoss: 0.034970\n",
      "Train Epoch: 49 [17920/60000 (30%)]\tLoss: 0.045792\n",
      "Train Epoch: 49 [20480/60000 (34%)]\tLoss: 0.058130\n",
      "Train Epoch: 49 [23040/60000 (38%)]\tLoss: 0.015817\n",
      "Train Epoch: 49 [25600/60000 (43%)]\tLoss: 0.024601\n",
      "Train Epoch: 49 [28160/60000 (47%)]\tLoss: 0.002542\n",
      "Train Epoch: 49 [30720/60000 (51%)]\tLoss: 0.027239\n",
      "Train Epoch: 49 [33280/60000 (55%)]\tLoss: 0.087066\n",
      "Train Epoch: 49 [35840/60000 (60%)]\tLoss: 0.012107\n",
      "Train Epoch: 49 [38400/60000 (64%)]\tLoss: 0.009595\n",
      "Train Epoch: 49 [40960/60000 (68%)]\tLoss: 0.042432\n",
      "Train Epoch: 49 [43520/60000 (72%)]\tLoss: 0.027796\n",
      "Train Epoch: 49 [46080/60000 (77%)]\tLoss: 0.003280\n",
      "Train Epoch: 49 [48640/60000 (81%)]\tLoss: 0.026206\n",
      "Train Epoch: 49 [51200/60000 (85%)]\tLoss: 0.041658\n",
      "Train Epoch: 49 [53760/60000 (90%)]\tLoss: 0.007830\n",
      "Train Epoch: 49 [56320/60000 (94%)]\tLoss: 0.007658\n",
      "Train Epoch: 49 [58880/60000 (98%)]\tLoss: 0.013279\n",
      "\n",
      "Training set: Accuracy: 59426/60000 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 50):\n",
    "  train(epoch)\n",
    "  #test()\n",
    "  if(epoch % 10 == 0):\n",
    "    torch.save(network, '/kaggle/working/model_wresnet.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-07T05:40:16.214205Z",
     "iopub.status.busy": "2020-12-07T05:40:16.213396Z",
     "iopub.status.idle": "2020-12-07T05:40:16.218671Z",
     "shell.execute_reply": "2020-12-07T05:40:16.218159Z"
    },
    "papermill": {
     "duration": 0.44557,
     "end_time": "2020-12-07T05:40:16.218805",
     "exception": false,
     "start_time": "2020-12-07T05:40:15.773235",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"y_true = []\\ny_pred = []\\n\\ndata_mis = []\\n\\ndef test_conf():\\n  network.eval()\\n  test_loss = 0\\n  correct = 0\\n  with torch.no_grad():\\n    for inp, label in test_dataset:\\n        data = inp.to(device)\\n        target = (label - 5).to(device)\\n        output = network(data)\\n        test_loss += criterion(output, target).item()\\n        pred = output.data.max(1, keepdim=True)[1].flatten()\\n        correct += pred.eq(target.data.view_as(pred)).sum()\\n        \\n        y_true.append(target.cpu().numpy())\\n        y_pred.append(pred.cpu().numpy())\\n        \\n        idxs_mask = ((pred == target) == False).nonzero()\\n        if(len(idxs_mask) != 0):\\n            data_mis.append(inp[idxs_mask].numpy())\\n        \\n  test_loss /= len(test_dataset.dataset)\\n  test_losses.append(test_loss)\\n  print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format( \\n    test_loss, correct, len(test_dataset.dataset),\\n    100. * correct / len(test_dataset.dataset))) \\n\\ntest_conf()\\nfrom sklearn.metrics import confusion_matrix, classification_report\\ny_true = np.concatenate(np.squeeze(y_true)).ravel()\\ny_pred = np.concatenate(np.squeeze(y_pred)).ravel()\\nprint(classification_report(y_true, y_pred))\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"y_true = []\n",
    "y_pred = []\n",
    "\n",
    "data_mis = []\n",
    "\n",
    "def test_conf():\n",
    "  network.eval()\n",
    "  test_loss = 0\n",
    "  correct = 0\n",
    "  with torch.no_grad():\n",
    "    for inp, label in test_dataset:\n",
    "        data = inp.to(device)\n",
    "        target = (label - 5).to(device)\n",
    "        output = network(data)\n",
    "        test_loss += criterion(output, target).item()\n",
    "        pred = output.data.max(1, keepdim=True)[1].flatten()\n",
    "        correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "        \n",
    "        y_true.append(target.cpu().numpy())\n",
    "        y_pred.append(pred.cpu().numpy())\n",
    "        \n",
    "        idxs_mask = ((pred == target) == False).nonzero()\n",
    "        if(len(idxs_mask) != 0):\n",
    "            data_mis.append(inp[idxs_mask].numpy())\n",
    "        \n",
    "  test_loss /= len(test_dataset.dataset)\n",
    "  test_losses.append(test_loss)\n",
    "  print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format( \n",
    "    test_loss, correct, len(test_dataset.dataset),\n",
    "    100. * correct / len(test_dataset.dataset))) \n",
    "\n",
    "test_conf()\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "y_true = np.concatenate(np.squeeze(y_true)).ravel()\n",
    "y_pred = np.concatenate(np.squeeze(y_pred)).ravel()\n",
    "print(classification_report(y_true, y_pred))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-07T05:40:17.101931Z",
     "iopub.status.busy": "2020-12-07T05:40:17.100881Z",
     "iopub.status.idle": "2020-12-07T05:40:17.104621Z",
     "shell.execute_reply": "2020-12-07T05:40:17.105106Z"
    },
    "papermill": {
     "duration": 0.442796,
     "end_time": "2020-12-07T05:40:17.105236",
     "exception": false,
     "start_time": "2020-12-07T05:40:16.662440",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import matplotlib.pyplot as plt\\n\\n\\nfig = plt.figure(figsize=(20, 20))\\nfor i in range(12):\\n  plt.subplot(3,4,i+1)\\n  plt.tight_layout()\\n  plt.imshow(data_mis[i][0][0][0], cmap=\\'gray\\', interpolation=\\'none\\')\\n  plt.title(\"Ground Truth: {}\".format(example_targets[i]))\\n  plt.xticks([])\\n  plt.yticks([])'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "for i in range(12):\n",
    "  plt.subplot(3,4,i+1)\n",
    "  plt.tight_layout()\n",
    "  plt.imshow(data_mis[i][0][0][0], cmap='gray', interpolation='none')\n",
    "  plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-07T05:40:18.005311Z",
     "iopub.status.busy": "2020-12-07T05:40:18.001427Z",
     "iopub.status.idle": "2020-12-07T05:40:18.898110Z",
     "shell.execute_reply": "2020-12-07T05:40:18.896959Z"
    },
    "papermill": {
     "duration": 1.35418,
     "end_time": "2020-12-07T05:40:18.898237",
     "exception": false,
     "start_time": "2020-12-07T05:40:17.544057",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#torch.save(network, '/kaggle/working/model_wide_resnet_99.pth')\n",
    "torch.save(network, '/kaggle/working/model_wresnet_final.pth')\n",
    "#network = torch.load('/kaggle/working/model_resnet_99.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-07T05:40:19.787247Z",
     "iopub.status.busy": "2020-12-07T05:40:19.786286Z",
     "iopub.status.idle": "2020-12-07T05:40:19.788303Z",
     "shell.execute_reply": "2020-12-07T05:40:19.788799Z"
    },
    "papermill": {
     "duration": 0.446331,
     "end_time": "2020-12-07T05:40:19.788924",
     "exception": false,
     "start_time": "2020-12-07T05:40:19.342593",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#network = torch.load('../input/resnet-100/model_resnet_99 (4).pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-07T05:40:20.942841Z",
     "iopub.status.busy": "2020-12-07T05:40:20.942138Z",
     "iopub.status.idle": "2020-12-07T05:40:21.791890Z",
     "shell.execute_reply": "2020-12-07T05:40:21.790368Z"
    },
    "papermill": {
     "duration": 1.422213,
     "end_time": "2020-12-07T05:40:21.792024",
     "exception": false,
     "start_time": "2020-12-07T05:40:20.369811",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pickle.load(open('../input/ecse-551-f20-image-understanding/Test.pkl', 'rb' ), encoding='bytes')\n",
    "\n",
    "sub_dataset = MyDataset(data, np.zeros((len(data), 1)), transform=test_transform, idx=None)\n",
    "sub_dataset = DataLoader(sub_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-07T05:40:22.704367Z",
     "iopub.status.busy": "2020-12-07T05:40:22.703337Z",
     "iopub.status.idle": "2020-12-07T05:40:37.488312Z",
     "shell.execute_reply": "2020-12-07T05:40:37.487342Z"
    },
    "papermill": {
     "duration": 15.230398,
     "end_time": "2020-12-07T05:40:37.488439",
     "exception": false,
     "start_time": "2020-12-07T05:40:22.258041",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict():\n",
    "  predictions = []\n",
    "  network.eval()\n",
    "  with torch.no_grad():\n",
    "    for data, target in sub_dataset:\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        target = network(data)\n",
    "        target = target.data.max(1, keepdim=True)[1].cpu().numpy() + 5\n",
    "        predictions = np.append(predictions, target)\n",
    "  return predictions\n",
    "        \n",
    "predictions = predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-07T05:40:38.387410Z",
     "iopub.status.busy": "2020-12-07T05:40:38.385999Z",
     "iopub.status.idle": "2020-12-07T05:40:38.896419Z",
     "shell.execute_reply": "2020-12-07T05:40:38.896928Z"
    },
    "papermill": {
     "duration": 0.961453,
     "end_time": "2020-12-07T05:40:38.897065",
     "exception": false,
     "start_time": "2020-12-07T05:40:37.935612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict_dataset = MyDataset(data, predictions, transform=test_transform, idx=None)\n",
    "predict_dataset = DataLoader(predict_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "examples = enumerate(predict_dataset)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "  plt.subplot(2,3,i+1)\n",
    "  plt.tight_layout()\n",
    "  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "  plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-07T05:40:39.803556Z",
     "iopub.status.busy": "2020-12-07T05:40:39.802817Z",
     "iopub.status.idle": "2020-12-07T05:40:39.806990Z",
     "shell.execute_reply": "2020-12-07T05:40:39.807567Z"
    },
    "papermill": {
     "duration": 0.448812,
     "end_time": "2020-12-07T05:40:39.807736",
     "exception": false,
     "start_time": "2020-12-07T05:40:39.358924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8. 13.  5. ... 10. 10. 12.]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-07T05:40:40.715600Z",
     "iopub.status.busy": "2020-12-07T05:40:40.713044Z",
     "iopub.status.idle": "2020-12-07T05:40:41.378584Z",
     "shell.execute_reply": "2020-12-07T05:40:41.377502Z"
    },
    "papermill": {
     "duration": 1.108756,
     "end_time": "2020-12-07T05:40:41.378749",
     "exception": false,
     "start_time": "2020-12-07T05:40:40.269993",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "pd.DataFrame(predictions.astype(int)).to_csv('./output.csv', header=['class'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 19788.738797,
   "end_time": "2020-12-07T05:40:43.428611",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-12-07T00:10:54.689814",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
